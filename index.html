<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta http-equiv="Cache-Control" content="no-siteapp" />
    <meta name="keywords" content="Zhou, Jiahuan（周嘉欢）" />
    <title>PKU-OV3 周嘉欢主页</title>
    <link rel="stylesheet" href="common/css/bootstrap.min.css">
    <link rel="stylesheet" href="common/css/index.css">
    <style>
        /* 论文标签样式 */
        .tabs {
            display: flex;
            cursor: pointer;
            padding: 10px;
            background-color: rgb(255, 255, 255);
            border-radius: 8px;
        }
        .tab {
            margin-right: 10px;
            padding: 5px 20px;
            border-radius: 8px;
            font-size: 14px;
            background-color: #f0f0f0;
            color: #333;
            transition: background-color 0.3s, color 0.3s;
            font-weight: bold;
            border: 1px solid #ddd;
        }
        .tab.active {
            background-color: rgb(138, 38, 38);
            color: white;
            border: 1px solid rgb(138, 38, 38);
        }
        .tab:hover {
            background-color: #ddd;
        }
        .paper-list {
            display: none;
            margin-top: 20px;
        }
        .paper-list.active {
            display: block;
        }
        /* 新闻标签样式 */
        .news-item {
            display: none; /* 默认隐藏所有新闻 */
        }
        .show-more {
            cursor: pointer;
            color: blue;
            text-decoration: underline;
            margin-top: 20px;
            display: inline-block;
        }
        .show-less {
            cursor: pointer;
            color: blue;
            text-decoration: underline;
            margin-top: 20px;
            display: inline-block;
        }
        /* 提示框样式 */
        #notification {
            position: fixed;
            top: 20px;
            right: 20px;
            background-color: #4CAF50;
            color: white;
            padding: 10px;
            border-radius: 5px;
            display: none; /* 默认隐藏 */
            z-index: 1000;
        }
        /*标签样式*/
        .number-box {
            display: inline-block;
            width: 15px;
            height: 15px;
            line-height: 25px;
            text-align: center;
            border-radius: 3px;
            font-size: 16px;
            margin-right: 5px;
            color: white;
            font-weight: bold;
        }
        /*论文标签样式*/
        .circle-box {
            display: inline-block;
            width: 5px;
            height: 5px;
            line-height: 25px;
            text-align: center;
            border-radius: 5px;
            font-size: 16px;
            margin-right: 8px;
            margin-left: 6px;
            margin-top: 5px;
            margin-bottom: 5px;
            color: white;
            font-weight: bold;
        }
        .tag-container {
            display: inline-flex;
            align-items: center;
            margin-left: 10px;
            background-color: #f0f0f0; /* 灰色背景 */
            border-radius: 10px; /* 圆角 */
            border: 1px solid #ccc;
            padding-left: 10px;
        }
        .tag {
            font-size: 16px;
        }
        /*兴趣标签样式*/
        .box-container {
            display: flex;
            justify-content: space-between; /* 可以改为 'space-around' 或 'center' 以改变对齐方式 */
        }
        .box {
            font-size: 17px;
            width: 33%;  /* 每个div占30%的宽度 */
            padding: 0px;
            background-color: #ffffff;
            border: 1px solid #ffffff;
            text-align: left;
            border-radius: 5px;
        }
    </style>
</head>

<body>


<!-- Copyright � 2008. Spidersoft Ltd -->
<style>
A.applink:hover {border: 2px dotted #DCE6F4;padding:2px;background-color:#ffff00;color:green;text-decoration:none}
A.applink       {border: 2px dotted #DCE6F4;padding:2px;color:red;background:transparent;text-decoration:none}
A.info          {color:red;background:transparent;text-decoration:none}
A.info:hover    {color:green;background:transparent;text-decoration:underline}
</style>



    <div class="container-fluid" style="padding:0 10%;">
        <dic class="row">
            <div class="col-md-2 col-xs-2 col-sm-2 navbar-fixed-left" >
                <div class="warpper" >
                    <div class="logo" >
                    </div>
                    <ul class="nav nav-pills nav-stacked " >
                        <li role="presentation" class="active" ><a href="index.html">HOMEPAGE</a></li>
                        <li role="presentation"><a href="research.html">LAB HOMEPAGE</a></li>
                        <!-- <li role="presentation"><a href="https://qiweili00.github.io/homepage/indexCN.html">中文版本</a></li> -->
                    </ul>
                </div>
            </div>
            <div class="col-md-10 col-xs-10 col-sm-10 mb20" >
                <nav class="navbar navbar-default ">
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                          <span class="sr-only">Toggle navigation</span>
                        </button>
                      </div>
                    <div class="container-fluid " style="padding: 0 ;">
                      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1" >
                          <ul class="nav navbar-nav">
                              <li class="active"><a href="#personal">About Me</a></li>
                              <li><a href="#news">News</a></li>
                              <li><a href="#direct">Research Interests</a></li>
                              <li><a href="#paper">Publications</a></li>
                              <li><a href="#services">Academic Service</a></li>
                          </ul>
                      </div>
                    </div>
                </nav>
                <div class="content">
                    <p id="personal" style="height:4rem;margin: 0;">&nbsp;</p>
                    <section>
                        <div class="my-auto" style="font-size: large;">
                            <p align="center">
                                <img height="240" src="common/img/bio.jpg" alt hspace="9" width="180" align="right" border="0" />
                            </p>
                            <h3 class="mb-0">Zhou, Jiahuan（周嘉欢）</h3>
                            </br>
                            <p>Excellent Young Scientists Fund Program (Overseas) 国家级人才计划青年项目（海外）入选者, </p>
                            <p>Peking University Boya Young Fellow 北京大学博雅青年学者, </p>
                            <p>Wangxuan Institute of Computer Technology, Peking University. </p>
                            <p>Beijing, China </p>
                            <p>E-mail: <a href="mailto:jiahuanzhou@pku.edu.cn">jiahuanzhou@pku.edu.cn</a> </p>
                            <br>
                            <p align="justify" style="line-height: 30px;text-indent: 3.6rem;">
                                I am now a Tenure-track Assistant Professor (Ph.D. Advisor) in <a href="https://www.icst.pku.edu.cn/index.htm">Wangxuan Institute of Computer Technology</a>, <a href="https://www.pku.edu.cn/">Peking University</a>. I received my Ph.D. degree under the supervision of Prof.<a href="http://www.ece.northwestern.edu/~yingwu/">Ying Wu</a> from <a href="https://www.northwestern.edu/">Northwestern University</a> in 2018. Before coming to Northwestern, I received my B.E. degree in the <a href="https://www.au.tsinghua.edu.cn/">Automation Department</a> from <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, Beijing, China in 2013. Before joining Peking University, I was a Postdoctoral Fellow and Research Assistant Professor working with Prof.Ying Wu at Northwestern University. I have authored more than 50 papers in international journals and conferences including Nature Communications, Nature Synthesis, IEEE TPAMI, IJCV, IEEE TIP, IEEE TIFS, CVPR, ICCV, ECCV, ICLR, AAAI, ACM MM, and so on. I serve as an Area Chair for CVPR, ICML, NeurIPS, ICME, and ICPR, an Associate Editor of the Springer Journal of Machine Vision and Applications (MVA), a regular reviewer member for a number of journals and conferences, e.g., T-PAMI, IJCV, TIP, CVPR, ICCV, ECCV, NeurIPS, ICML, and so on.
                            </p>
                            <p align="justify" style="line-height: 30px;text-indent: 3.6rem;">
                                周嘉欢，北京大学王选计算机研究所研究员、助理教授、博士生导师，国家高层次青年人才，北京大学小米博雅青年学者。2013年本科毕业于清华大学自动化系，2018年博士毕业于美国西北大学计算机科学专业。主要研究方向为计算机视觉、机器学习、人工智能等，已发表Nature子刊、CCF-A和IEEE Trans论文五十余篇，包括Nature Communications、Nature Synthesis、IEEE TPAMI、IJCV、IEEE TIP、IEEE TIFS、CVPR、ICCV、ECCV、ICLR、AAAI、ACM MM等领域内顶级期刊和会议论文。主持包括国家自然科学基金优秀青年科学基金项目（海外）、国家自然基金委面上项目、某基础加强技术领域基金、全国重点实验室基金、多项校企合作项目等。担任CCF-CV、CSF-VCS专委会委员，国际期刊Machine Vision and Applications编委、国际会议CVPR、ICML、NeurIPS、ICME、ICPR领域主席，AAAI程序委员会委员。
                            </p>
                        </div>
                    </section>
                    <p id="news" style="height:4rem;margin: 0;">&nbsp;</p>
                    <section style="font-size: 1.8rem;">
                        <h3 >News</h3>
                        <ul>
                            <li class="news-item"><p style="color:red;">We are always actively recruiting Post-doc Fellows, Ph.D., Master, and Research Interns! Welcome to contact me with your detailed CV! (常年招收博士后、博士、硕士和科研实习生！)</p>
                            </li>
                            <li class="news-item"><p>02.2025, Four papers are accepted by CVPR'2025.</p>
                            </li>
                            <li class="news-item"><p>02.2025, Invited to serve as the Area Chair of NeurlPS'2025.</p>
                            </li>
                            <li class="news-item"><p>01.2025, One paper is accepted by ICLR'2025.</p>
                            </li>
                            <li class="news-item"><p>01.2025, One paper is accepted by IEEE TIFS.</p>
                            </li>
                            <li class="news-item"><p>12.2024, One paper is accepted by Nature Communications</p>
                            </li>
                            <li class="news-item"><p>12.2024, Invited to serve as the Area Chair of ICML'2025.</p>
                            </li>
                            <li class="news-item"><p>12.2024, Four papers are accepted by AAAI'2025.</p>
                            </li>
                            <li class="news-item"><p>09.2024, Invited to serve as the Area Chair of CVPR'2025.</p>
                            </li>
                            <li class="news-item"><p>07.2024, Four papers are accepted by ACM MM'2024.</p>
                            </li>
                            <li class="news-item"><p>05.2024, One paper is accepted by IJCV.</p>
                            </li>
                            <li class="news-item"><p>05.2024, Invited to serve as the Area Chair of NeurIP'2024.</p>
                            </li>
                            <li class="news-item"><p>04.2024, One paper is accepted by IJCV.</p>
                            </li>                     
                            <li class="news-item"><p>04.2024, One paper is accepted by IJCAI'2024.</p>
                            </li>
                            <li class="news-item"><p>03.2024, One paper is accepted by Nature Synthesis.</p>
                            </li>
                            <li class="news-item"><p>02.2024, Four papers are accepted by CVPR'2024.</p>
                            </li>
                            <li class="news-item"><p>01.2024, One paper is accepted by IEEE TPAMI.</p>
                            </li>
                            <li class="news-item"><p>12.2023, One paper is accepted by ACM TOMM.</p>
                            </li>
                            <li class="news-item"><p>12.2023, Five papers are accepted by AAAI'2024.</p>
                            </li>
                            <li class="news-item"><p>12.2023, Invited to serve as the Area Chair of ICPR'2024.</p>
                            </li>
                            <li class="news-item"><p>11.2023, One paper is accepted by IEEE TIFS.</p>
                            </li>
                            <li class="news-item"><p>09.2023, One paper is accepted by ICIG'2023.</p>
                            </li>
                            <li class="news-item"><p>07.2023, One paper is accepted by ACM MM'2023.</p>
                            </li>
                            <li class="news-item"><p>06.2023, Invited to serve as the Area Chair of CVPR'2024.</p>
                            </li>
                            <li class="news-item"><p>03.2023, One paper is accepted by IEEE TCSVT.</p>
                            </li>
                            <li class="news-item"><p>01.2023, One paper is accepted by IEEE TCSVT.</p>
                            </li>
                            <li class="news-item"><p>12.2022, Invited to serve as the Session Chair of VCIP'2022.</p>
                            </li>
                            <li class="news-item"><p>12.2022, Invited to serve as the Area Chair of ICME'2023.</p>
                            </li>
                            <li class="news-item"><p>11.2022, One paper is accepted by AAAI'2023.</p>
                            </li>
                            <li class="news-item"><p>10.2022, Awarded National Young Scientists Funding Program.</p>
                            </li>
                            <li class="news-item"><p>09.2022, Invited to serve as the Area Chair of CVPR'2023.</p>
                            </li>
                            <li class="news-item"><p>08.2022, One paper is accepted by IEEE TPAMI.</p>
                            </li>
                            <li class="news-item"><p>07.2022, One paper is accepted by ECCV'2022.</p>
                            </li>
                            <li class="news-item"><p>04.2022, Invited to serve as the Area Chair of ICPR'2023.</p>
                            </li>
                            <li class="news-item"><p>03.2022, Joined Peking University.</p>
                            </li>
                        </ul>
                        <div id="show-more" class="show-more" onclick="showMoreNews()">Show More</div>
                        <div id="show-less" class="show-less" onclick="showLessNews()">Show Less</div>
                    </section>
                    <p id="direct" style="height:4rem;margin: 0;">&nbsp;</p>
                    <section style="font-size: 1.7rem;">
                        <h3>Research Interests</h3>
                        <div class="box-container">
                            <div class="box">
                                <div class="circle-box" style="background-color: rgb(0, 0, 0);"></div><b>Open-Environment Computer Vision</b><br>
                                <div class="number-box" style="background-color: rgb(255, 0, 0);"></div>Object Re-Identification<br>
                                <div class="number-box" style="background-color: rgb(255, 80, 80);"></div>Fine-grained Recogniiton<br>
                                <div class="number-box" style="background-color: rgb(255, 150, 150);"></div>Object Detection<br>
                                <div class="number-box" style="background-color: rgb(255, 224, 224);"></div>AIGC
                            </div>
                            <div class="box"><div class="circle-box" style="background-color: rgb(0, 0, 0);"></div><b>Efficient Learning from Limited Data</b><br>
                                <div class="number-box" style="background-color: rgb(0, 0, 255);"></div>Zero/Few-shot Learning<br>
                                <div class="number-box" style="background-color: rgb(50, 50, 255);"></div>Incremental Learning<br>
                                <div class="number-box" style="background-color: rgb(100, 100, 255);"></div>Prompt Learning<br>
                                <div class="number-box" style="background-color: rgb(150, 150, 255);"></div>Online Learning<br>
                                <div class="number-box" style="background-color: rgb(200, 200, 255);"></div>Noisy Learning
                            </div>
                            <div class="box"><div class="circle-box" style="background-color: rgb(0, 0, 0);"></div><b>Multi-Modal Learning</b><br>
                            <div class="number-box" style="background-color: rgb(100, 50, 0);"></div>Visual-Language<br>
                            <div class="number-box" style="background-color: rgb(150, 100, 0);"></div>2D to 3D<br>
                            <div class="number-box" style="background-color: rgb(200, 150, 0);"></div>Visible to Thermal<br>
                            <div class="number-box" style="background-color: rgb(250, 200, 0);"></div>Sketch to Photo
                            </div>
                        </div>
                       
                    </section>
                    
                    <p id="paper" style="height:4rem;margin: 0;">&nbsp;</p>
                    <section style="font-size: 1.8rem;">
                        <h3>Publications</h3>
                        <div class="tabs">
                            <div class="tab" onclick="showPapers('0000')">All Papers</div>
                            <div class="tab" onclick="showPapers('2025')">2025</div>
                            <div class="tab" onclick="showPapers('2024')">2024</div>
                            <div class="tab" onclick="showPapers('2023')">2023</div>
                            <div class="tab" onclick="showPapers('2022')">2022 and before</div>
                        </div>
                        
                        <div id="notification">The bib of the selected paper has copied!</div>

                        <div id="0000" class="paper-list">
                            <ol> 
                                <li><p align="justify">(<i><strong>CVPR'25</strong></i>)-Zichen Liu, Kunlun Xu, Bing Su, Xu Zou, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding", in 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville TN, Jun.11 - Jun.15, 2025
                                    <br>[<a href="https://arxiv.org/abs/2503.15973">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/CVPR2025-STOP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@misc{liu2025stopintegratedspatialtemporaldynamic,title={STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding}, author={Zichen Liu and Kunlun Xu and Bing Su and Xu Zou and Yuxin Peng and Jiahuan Zhou},year={2025},eprint={2503.15973},archivePrefix={arXiv},primaryClass={cs.CV}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                </p>
                                </li>

                                <li><p align="justify">(<i><strong>CVPR'25</strong></i>)-Chenyu Zhang, Kunlun Xu, Zichen Liu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "SCAP: Transductive Test-Time Adaptation via Supportive Clique-based Attribute Prompting", in 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville TN, Jun.11 - Jun.15, 2025
                                    <br>[<a href=" https://arxiv.org/abs/2503.12866">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/CVPR2025-SCAP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{zhang2025scap,title={SCAP: Transductive Test-Time Adaptation via Supportive Clique-based Attribute Prompting},author={Zhang, Chenyu and Xu, Kunlun and Liu, Zichen and Peng, Yuxin and Zhou, Jiahuan},journal={arXiv preprint arXiv:2503.12866},year={2025}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                </p>
                                </li>

                                <li><p align="justify">(<i><strong>CVPR'25</strong></i>)-Mingfu Liang, <b>Jiahuan Zhou*</b>, Xu Zou, and Ying Wu, "Incremental Object Keypoint Learning", in 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville TN, Jun.11 - Jun.15, 2025
                                    <br>[<a href="">pdf</a>] [<a href="">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                </p>
                                </li>

                                <li><p align="justify">(<i><strong>CVPR'25</strong></i>)-Zhenyu Cui, <b>Jiahuan Zhou</b>, and Yuxin Peng, "DKC: Differentiated Knowledge Consolidation for Cloth-Hybrid Lifelong Person Re-identification", in 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville TN, Jun.11 - Jun.15, 2025
                                    <br>[<a href="">pdf</a>] [<a href="">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>


                                <li><p align="justify">(<i><strong>ICLR'25</strong></i>)-Yanjie Wang, Liqun Chen, Tianming Zhao, Tao Zhang, Guodong Wang, Luxin Yan, Sheng Zhong, <b>Jiahuan Zhou*</b>, and Xu Zou*, "High-dimension Prototype is a Better Incremental Object Detection Learner", in the 13th International Conference on Learning Representations, Singapore, Apr.24 - Apr.28, 2025
                                    <br>[<a href="https://openreview.net/pdf?id=6T8czSBWce">pdf</a>] [<a href="">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>TIFS'25</strong></i>)-Xinyue Zhang, <b>Jiahuan Zhou</b>, Luxin Yan, Sheng Zhong, and Xu Zou, "Hunt Camouflaged Objects via Revealing Mutation Regions", in IEEE Transactions on Information Forensics and Security, 2025
                                    <br>[<a href="https://www.researchgate.net/publication/388091247_Hunt_Camouflaged_Objects_via_Revealing_Mutation_Regions">pdf</a>] [<a href="">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{article, author = {Zhang, Xinyue and Zhou, Jiahuan and Yan, Luxin and Zhong, Sheng and Zou, Xu}, year = {2025}, month = {01}, pages = {1-1}, title = {Hunt Camouflaged Objects via Revealing Mutation Regions}, volume = {PP}, journal = {IEEE Transactions on Information Forensics and Security}, doi = {10.1109/TIFS.2025.3530703}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'25</strong></i>)-Kunlun Xu, Chenghao Jiang, Peixi Xiong, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "DASK: Distribution Rehearsing via Adaptive Style Kernel Learning for Exemplar-Free Lifelong Person Re-Identification", in 39th Annual AAAI Conference on Artificial Intelligence, Philadelphia, Pennsylvania, USA, Feb.25 - Mar.4, 2025
                                    <br>[<a href="https://arxiv.org/pdf/2412.09224">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/AAAI2025-LReID-DASK">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{xu2024dask, title={DASK: Distribution Rehearsing via Adaptive Style Kernel Learning for Exemplar-Free Lifelong Person Re-Identification}, author={Xu, Kunlun and Jiang, Chenghao and Xiong, Peixi and Peng, Yuxin and Zhou, Jiahuan}, journal={arXiv preprint arXiv:2412.09224}, year={2024}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'25</strong></i>)-Yifeng Yao, Zichen Liu, Zhenyu Cui, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Selective Visual Prompting in Vision Mamba", in 39th Annual AAAI Conference on Artificial Intelligence, Philadelphia, Pennsylvania, USA, Feb.25 - Mar.4, 2025
                                    <br>[<a href="https://arxiv.org/pdf/2412.08947">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/AAAI2025-SVP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{yao2024selective, title={Selective Visual Prompting in Vision Mamba}, author={Yao, Yifeng and Liu, Zichen and Cui, Zhenyu and Peng, Yuxin and Zhou, Jiahuan}, journal={arXiv preprint arXiv:2412.08947}, year={2024}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'25</strong></i>)-Qiwei Li, and <b>Jiahuan Zhou*</b>, "CAPrompt: Cyclic Prompt Aggregation for Pre-Trained Model Based Class Incremental Learning", in 39th Annual AAAI Conference on Artificial Intelligence, Philadelphia, Pennsylvania, USA, Feb.25 - Mar.4, 2025
                                    <br>[<a href="https://arxiv.org/pdf/2412.08929">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/AAAI2025-CAPrompt">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{li2024caprompt, title={CAPrompt: Cyclic Prompt Aggregation for Pre-Trained Model Based Class Incremental Learning}, author={Li, Qiwei and Zhou, Jiahuan}, journal={arXiv preprint arXiv:2412.08929}, year={2024}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'25</strong></i>)-Yiyuan Liang, Liqun Chen, Zhiying Yan, <b>Jiahuan Zhou</b>, Luxin Yan, Sheng Zhong, and Xu Zou, "DriveEditor: 3D Information Guided Controllable Object Editing in Driving Scene", in 39th Annual AAAI Conference on Artificial Intelligence, Philadelphia, Pennsylvania, USA, Feb.25 - Mar.4, 2025
                                    <br>[<a href="https://arxiv.org/pdf/2412.19458">pdf</a>] [<a href="https://github.com/yvanliang/DriveEditor">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{liang2024driveeditor, title={DriveEditor: A Unified 3D Information-Guided Framework for Controllable Object Editing in Driving Scenes}, author={Liang, Yiyuan and Yan, Zhiying and Chen, Liqun and Zhou, Jiahuan and Yan, Luxin and Zhong, Sheng and Zou, Xu}, journal={arXiv preprint arXiv:2412.19458}, year={2024}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                </p>
                                </li>





                                
                                <li><p align="justify">(<i><strong>Nat. Commun'24</strong></i>)-Ziyi Han, Shengqiang Wu, Chun Huang, Fengyuan Xuan, Xiaocang Han, Yinfeng Long, Qing Zhang, Junxian Li, Yuan Meng, Lin Wang, <b>Jiahuan Zhou</b>, Wenping Hu, Jingsi Qiao, Dechao Geng, and Xiaoxu Zhao, "Atomically engineering interlayer symmetry operations of two-dimensional crystals", in Nature Communications, 2024, vol. 15, no. 1, pp. 10835, Doi: 10.1038/s41467-024-55130-z
                                    <br>[<a href="https://www.nature.com/articles/s41467-024-55130-z.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{han2024atomically, title={Atomically engineering interlayer symmetry operations of two-dimensional crystals}, author={Han, Ziyi and Wu, Shengqiang and Huang, Chun and Xuan, Fengyuan and Han, Xiaocang and Long, Yinfeng and Zhang, Qing and Li, Junxian and Meng, Yuan and Wang, Lin and others}, journal={Nature Communications}, volume={15}, number={1}, pages={10835}, year={2024}, publisher={Nature Publishing Group UK London}}')">bib</a>]
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ACM MM'24</strong></i>)-Qiwei Li, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Progressive Prototype Evolving for Dual-Forgetting Mitigation in Non-Exemplar Online Continual Learning", in 32nd ACM Multimedia Conference, Melbourne, Australia, 2024
                                    <br>[<a href="pub/2024 ACM MM Progressive Prototype Evolving for Dual-Forgetting Mitigation in Non-Exemplar Online Continual Learning.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/MM2024-PPE">code</a>] [<a href="#" onclick="copyTextAndNotify(event, 'This bib is currently unavaliable')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ACM MM'24</strong></i>)-Kunlun Xu, Haozhuo Zhang, Yu Li, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Mitigate Catastrophic Remembering via Continual Knowledge Purification for Noisy Lifelong Person Re-Identification", in 32nd ACM Multimedia Conference, Melbourne, Australia, 2024
                                    <br>[<a href="pub/2024 ACM MM Mitigate Catastrophic Remembering via Continual Knowledge Purification for Noisy Lifelong Person Re-Identification.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/MM2024-CKP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, 'This bib is currently unavaliable')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(200, 200, 255);"></span>
                                        <span class="tag">NL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ACM MM'24</strong></i>)-Zichen Liu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "InsVP: Efficient Instance Visual Prompting from Image Itself", in 32nd ACM Multimedia Conference, Melbourne, Australia, 2024
                                    <br>[<a href="pub/2024 ACM MM InsVP  Efficient Instance Visual Prompting from Image Itself.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/MM2024-InsVP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, 'This bib is currently unavaliable')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ACM MM'24</strong></i>)-Qiwen Zhu, Yanjie Wang, Shilv Cai, Liqun Chen, <b>Jiahuan Zhou</b>, Luxin Yan, Sheng Zhong, and Xu Zou, "Perceptual-Distortion Balanced Image Super-Resolution is a Multi-Objective Optimization Problem", in 32nd ACM Multimedia Conference, Melbourne, Australia, 2024
                                    <br>[<a href="pub/2024 ACM MM Perceptual-Distortion Balanced Image Super-Resolution is a Multi-Objective Optimization Problem.pdf">pdf</a>] [<a href="https://github.com/ZhuKeven/MOBOSR">code</a>] [<a href="#" onclick="copyTextAndNotify(event, 'This bib is currently unavaliable')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>IJCV'24</strong></i>)-Zichen Liu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Compositional Prompting for Anti-Forgetting in Domain Incremental Learning", in International Journal of Computer Vision, 2024, pp. 1-18, Doi: 10.1007/s11263-024-02134-3
                                    <br>[<a href="pub/2024 IJCV Compositional Prompting for Anti-Forgetting in Domain Incremental Learning.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/IJCV2024-C-Prompt">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{liu2024compositional,\n  title={Compositional Prompting for Anti-Forgetting in Domain Incremental Learning},\n  author={Liu, Zichen and Peng, Yuxin and Zhou, Jiahuan},\n  journal={International Journal of Computer Vision},\n  pages={1--18},\n  year={2024},\n  publisher={Springer}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>IJCV'24</strong></i>)-Qiwei Li, Kunlun Xu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Exemplar-Free Lifelong Person Re-Identification via Prompt-guided Adaptive Knowledge Consolidation", in International Journal of Computer Vision, 2024, pp. 1-16, Doi: 10.1007/s11263-024-02110-x
                                    <br>[<a href="pub/2024 IJCV Exemplar-Free Lifelong Person Re-Identification via Prompt-guided Adaptive Knowledge Consolidation.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/IJCV2024-PAEMA/">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{li2024exemplar,\n  title={Exemplar-Free Lifelong Person Re-identification via Prompt-Guided Adaptive Knowledge Consolidation},\n  author={Li, Qiwei and Xu, Kunlun and Peng, Yuxin and Zhou, Jiahuan},\n  journal={International Journal of Computer Vision},\n  pages={1--16},\n  year={2024},\n  publisher={Springer}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>IJCAI'24</strong></i>)-Hongbo Sun, <b>Jiahuan Zhou</b>, Xiangteng He, Jinglin Xu, and Yuxin Peng, "FineFMPL: Fine-grained Feature Mining Prompt Learning for Few-Shot Class Incremental Learning", in 2024 International Joint Conference on Artificial Intelligence, Jeju, South Korea, 2024
                                    <br>[<a href="pub/IJCAI2024_FineFMPL.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{sunfinefmpl,\n  title={FineFMPL: Fine-grained Feature Mining Prompt Learning for Few-Shot Class Incremental Learning},\n  author={Sun, Hongbo and Zhou, Jiahuan and He, Xiangteng and Xu, Jinglin and Peng, Yuxin}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 80, 80);"></span>
                                        <span class="tag">FR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(0, 0, 255);"></span>
                                        <span class="tag">Z/F L &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>Nat. Synth'24</strong></i>)-Xiaocang Han, Mengmeng Niu, Yan Luo, Runlai Li, Jiadong Dan, Yanhui Hong, Xu Wu, Alex V. Trukhanov, Wei Ji, Yeliang Wang, <b>Jiahuan Zhou</b>, Jingsi Qiao, Jin Zhang, and Xiaoxu Zhao, "Atomically engineering metal vacancies in monolayer transition metal dichalcogenides" in Nature Synthesis, 2024, Doi: 10.1038/s44160-024-00501-z
                                    <br>[<a href="pub/2024 Nature Synthesis Atomically engineering metal vacancies in monolayer transition metal dichalcogenides.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{han2024atomically,\n  title={Atomically engineering metal vacancies in monolayer transition metal dichalcogenides},\n  author={Han, Xiaocang and Niu, Mengmeng and Luo, Yan and Li, Runlai and Dan, Jiadong and Hong, Yanhui and Wu, Xu and Trukhanov, Alex V and Ji, Wei and Wang, Yeliang and others},\n  journal={Nature Synthesis},\n  volume={3},\n  number={5},\n  pages={586--594},\n  year={2024},\n  publisher={Nature Publishing Group UK London}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'24</strong></i>)-Kunlun Xu, Xu Zou, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Distribution-aware Knowledge Prototyping for Non-exemplar Lifelong Person Re-identification", in 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle WA, USA, 2024, pp. 16604-16613
                                    <br>[<a href="pub/CVPR2024_DKP.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/CVPR2024-DKP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{xu2024distribution,\n  title={Distribution-aware Knowledge Prototyping for Non-exemplar Lifelong Person Re-identification},\n  author={Xu, Kunlun and Zou, Xu and Peng, Yuxin and Zhou, Jiahuan},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={16604--16613},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'24</strong></i>)-Qiwei Li, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "FCS: Feature Calibration and Separation for Non-Exemplar Class Incremental Learning", in 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle WA, USA, 2024, pp. 28495-28504
                                    <br>[<a href="pub/CVPR2024_FCS.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/CVPR2024-FCS">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{li2024fcs,\n  title={FCS: Feature Calibration and Separation for Non-Exemplar Class Incremental Learning},\n  author={Li, Qiwei and Peng, Yuxin and Zhou, Jiahuan},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={28495--28504},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'24</strong></i>)-Yanjie Wang, Xu Zou, Luxin Yan, Sheng Zhong, and <b>Jiahuan Zhou</b>, "SNIDA: Unlocking Few-Shot object Detection with Non-linear Semantic Decoupling Augmentation", in 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle WA, USA, 2024, pp. 12544-12553
                                    <br>[<a href="pub/CVPR2024_SNIDA.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{wang2024snida,\n  title={SNIDA: Unlocking Few-Shot Object Detection with Non-linear Semantic Decoupling Augmentation},\n  author={Wang, Yanjie and Zou, Xu and Yan, Luxin and Zhong, Sheng and Zhou, Jiahuan},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={12544--12553},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(0, 0, 255);"></span>
                                        <span class="tag">Z/F L &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'24</strong></i>)-Zhenyu Cui, <b>Jiahuan Zhou</b>, Xun Wang, Manyu Zhu, and Yuxin Peng, "Learning Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification", in 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle WA, USA, 2024, pp. 16614-16623
                                    <br>[<a href="pub/CVPR2024_C2R.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/C2R_CVPR2024">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{cui2024learning,\n  title={Learning Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification},\n  author={Cui, Zhenyu and Zhou, Jiahuan and Wang, Xun and Zhu, Manyu and Peng, Yuxin},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={16614--16623},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TPAMI'24</strong></i>)-Shilv Cai, Liqun Chen, Zhijun Zhang, Xiangyun Zhao, and <b>Jiahuan Zhou</b>, Yuxin Peng, Luxin Yan, Sheng Zhong, and Xu Zou, "I2C: Invertible Continuous Codec for High-Fidelity Variable-Rate Image Compression", in IEEE Transactions on Pattern Analysis & Machine Intelligence, 2024, vol. 46, no. 6, pp. 4262-4279, Doi: 10.1109/TPAMI.2024.3356557
                                    <br>[<a href="pub/TPAMI2024_I2C.pdf">pdf</a>] [<a href="https://github.com/CaiShilv/HiFi-VRIC">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{cai2024i2c,\n  title={I2C: Invertible Continuous Codec for High-Fidelity Variable-Rate Image Compression},\n  author={Cai, Shilv and Chen, Liqun and Zhang, Zhijun and Zhao, Xiangyun and Zhou, Jiahuan and Peng, Yuxin and Yan, Luxin and Zhong, Sheng and Zou, Xu},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n  year={2024},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TOMM'24</strong></i>)-Yanzhe Chen, <b>Jiahuan Zhou</b>, and Yuxin Peng, "SPIRIT: Style-guided Patch Interaction for Fashion Image Retrieval with Text Feedback", in ACM Transactions on Multimedia Computing, Communications, and Applications, 2024, pp. 1-17, Doi: 10.1145/3640345
                                    <br>[<a href="pub/2024 ToMM SPIRIT  Style-guided Patch Interaction for Fashion Image Retrieval with Text Feedback.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/SPIRIT_TOMM2024">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{chen2024spirit,\n  title={SPIRIT: Style-guided Patch Interaction for Fashion Image Retrieval with Text Feedback},\n  author={Chen, Yanzhe and Zhou, Jiahuan and Peng, Yuxin},\n  journal={ACM Transactions on Multimedia Computing, Communications and Applications},\n  volume={20},\n  number={6},\n  pages={1--17},\n  year={2024},\n  publisher={ACM New York, NY}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 50, 0);"></span>
                                        <span class="tag">V&L &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Kunlun Xu, Xu Zou, and <b>Jiahuan Zhou*</b>, "LSTKC: Long Short-Term Knowledge Consolidation for Lifelong Person Re-Identification", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, vol. 38, no. 14, pp. 16202-16210, Doi: 10.1609/aaai.v38i14.29554
                                    <br>[<a href="pub/AAAI2024_LSTK.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/LSTKC">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{xu2024lstkc,\n  title={LSTKC: Long Short-Term Knowledge Consolidation for Lifelong Person Re-identification},\n  author={Xu, Kunlun and Zou, Xu and Zhou, Jiahuan},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={14},\n  pages={16202--16210},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Zichen Liu, Hongbo Sun, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "DART: Dual-Modal Adaptive Online Prompting and Knowledge Retention for Test-Time Adaptation", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, Vol. 38, No. 14, pp. 16202-16210, Doi: 10.1609/aaai.v38i14.29554
                                    <br>[<a href="pub/AAAI2024_DART.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/DART">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{liu2024dart,\n  title={DART: Dual-Modal Adaptive Online Prompting and Knowledge Retention for Test-Time Adaptation},\n  author={Liu, Zichen and Sun, Hongbo and Peng, Yuxin and Zhou, Jiahuan},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={13},\n  pages={14106--14114},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Zhenyu Cui, Yuxin Peng, Xun Wang, Manyu Zhu, and <b>Jiahuan Zhou</b>, "Continual Vision-Language Retrieval via Dynamic Knowledge Rectification", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, Vol. 38, No. 10, pp. 11704-11712, Doi: 10.1609/aaai.v38i10.29054
                                    <br>[<a href="pub/AAAI2024_CVLR.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{cui2024continual,\n  title={Continual Vision-Language Retrieval via Dynamic Knowledge Rectification},\n  author={Cui, Zhenyu and Peng, Yuxin and Wang, Xun and Zhu, Manyu and Zhou, Jiahuan},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={10},\n  pages={11704--11712},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 50, 0);"></span>
                                        <span class="tag">V&L &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Yanzhe Chen, Huasong Zhong, Xiangteng He, Yuxin Peng, <b>Jiahuan Zhou</b>, and Lele Cheng, "FashionERN: Enhance-and-Refine Network for Composed Fashion Image Retrieval", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, Vol. 38, No. 2, pp. 1228-1236, Doi:10.1609/aaai.v38i2.27885
                                    <br>[<a href="pub/AAAI2024_FASHIONERN.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{chen2024fashionern,\n  title={FashionERN: Enhance-and-Refine Network for Composed Fashion Image Retrieval},\n  author={Chen, Yanzhe and Zhong, Huasong and He, Xiangteng and Peng, Yuxin and Zhou, Jiahuan and Cheng, Lele},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={2},\n  pages={1228--1236},\n  year={2024}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Shilv Cai, Liqun Chen, Sheng Zhong, Luxin Yan, <b>Jiahuan Zhou</b>, and Xu Zou, "Make Lossy Compression Meaningful for Low-light Images", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, Vol. 38, No. 8, pp. 8236-8245, Doi: 10.1609/aaai.v38i8.28664
                                    <br>[<a href="pub/AAAI2024_MAKE.pdf">pdf</a>] [<a href="https://github.com/CaiShilv/Joint-IC-LL">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{cai2024make,\n  title={Make Lossy Compression Meaningful for Low-Light Images},\n  author={Cai, Shilv and Chen, Liqun and Zhong, Sheng and Yan, Luxin and Zhou, Jiahuan and Zou, Xu},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={8},\n  pages={8236--8245},\n  year={2024}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TIFS'24</strong></i>)-Zhenyu Cui, <b>Jiahuan Zhou</b>, and Yuxin Peng, "DMA: Dual Modality-Aware Alignment for Visible-Infrared Person Re-Identification", in IEEE Transactions on Information Forensics and Security, 2024, Vol. 19, pp. 2696-2708, doi: 10.1109/TIFS.2024.3352408
                                    <br>[<a href="pub/TIFS2023_DMA.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/DMA_TIFS2023">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{cui2024dma,\n  title={DMA: Dual Modality-Aware Alignment for Visible-Infrared Person Re-Identification},\n  author={Cui, Zhenyu and Zhou, Jiahuan and Peng, Yuxin},\n  journal={IEEE Transactions on Information Forensics and Security},\n  year={2024},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(200, 150, 0);"></span>
                                        <span class="tag">V2T &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>计算机科学'24</strong></i>)-崔振宇, <b>周嘉欢</b>, 彭宇新, "跨模态目标重识别研究综述", 计算机科学 (创刊50周年特别专题综述论文), 2024, Vol. 51, No.1, pp. 13-25.
                                    <br>[<a href="https://www.jsjkx.com/CN/10.11896/jsjkx.yg20240103">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{cui2024cross,\n  title={跨模态目标重识别研究综述},\n  author={Cui, Zhenyu and Zhou, Jiahuan and Peng, Yuxin},\n  journal={计算机科学},\n  volume={51},\n  number={1},\n  pages={13--25},\n  year={2024},\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(200, 150, 0);"></span>
                                        <span class="tag">V2T &nbsp;</span>
                                    </span>
                                </p>
                                </li>



                                <li><p align="justify">(<i><strong>ACM MM'23</strong></i>)-Hongbo Sun, Xiangteng He, <b>Jiahuan Zhou</b>, and Yuxin Peng, "Fine-Grained Visual Prompt Learning of Vision-Language Models for Image Recognition", in 31st ACM Multimedia Conference, Ottawa, Canada, Oct.29 - Nov.3, 2023, pp. 5828-5836, Doi: 10.1145/3581783.3612403
                                    <br>[<a href="pub/MM2023_Finegrained.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{sun2023fine,\n  title={Fine-grained visual prompt learning of vision-language models for image recognition},\n  author={Sun, Hongbo and He, Xiangteng and Zhou, Jiahuan and Peng, Yuxin},\n  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},\n  pages={5828--5836},\n  year={2023}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 80, 80);"></span>
                                        <span class="tag">FR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 50, 0);"></span>
                                        <span class="tag">V&L &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICIG'23</strong></i>)-Kunlun Xu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Uncover the Body: Occluded Person Re-identification via Masked Image Modeling", in 12rd International Conference on Image and Graphics, Nanjing, China, Sep.22 - 24, 2023, pp. 241-253, Doi: 10.1007/978-3-031-46305-1_20
                                    <br>[<a href="pub/ICIG2023_Uncover.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{xu2023uncover,\n  title={Uncover the Body: Occluded Person Re-identification via Masked Image Modeling},\n  author={Xu, Kunlun and Peng, Yuxin and Zhou, Jiahuan},\n  booktitle={International Conference on Image and Graphics},\n  pages={241--253},\n  year={2023},\n  organization={Springer}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>TCSVT'23</strong></i>)-Zeqi Chen, Zhichao Cui, Chi Zhang, <b>Jiahuan Zhou</b>, and Yuehu Liu, "Dual Clustering Co-teaching with Consistent Sample Mining for Unsupervised Person Re-Identification", in IEEE Transactions on Circuits and Systems for Video Technology, 2023, vol. 33, no. 10, pp. 5908-5920, Doi: 10.1109/TCSVT.2023.3261898
                                    <br>[<a href="pub/TCSVT2023_Dual.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{chen2023dual,\n  title={Dual clustering co-teaching with consistent sample mining for unsupervised person re-identification},\n  author={Chen, Zeqi and Cui, Zhichao and Zhang, Chi and Zhou, Jiahuan and Liu, Yuehu},\n  journal={IEEE Transactions on Circuits and Systems for Video Technology},\n  volume={33},\n  number={10},\n  pages={5908--5920},\n  year={2023},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>TCSVT'23</strong></i>)-Zhenyu Cui, <b>Jiahuan Zhou</b>, Yuxin Peng, Shiliang Zhang, and Yaowei Wang, "DCR-ReID: Deep Component Reconstruction for Cloth-Changing Person Re-Identification", in IEEE Transactions on Circuits and Systems for Video Technology, 2023, vol. 33, no. 8, pp. 4415-4428, Doi: 10.1109/TCSVT.2023.3241988
                                    <br>[<a href="pub/TCSVT2023_DCR.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/DCR-ReID_TCSVT2023">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{cui2023dcr,\n  title={Dcr-reid: Deep component reconstruction for cloth-changing person re-identification},\n  author={Cui, Zhenyu and Zhou, Jiahuan and Peng, Yuxin and Zhang, Shiliang and Wang, Yaowei},\n  journal={IEEE Transactions on Circuits and Systems for Video Technology},\n  volume={33},\n  number={8},\n  pages={4415--4428},\n  year={2023},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'23</strong></i>)-MengShun Hu, Kui Jiang, Zhixiang Nie, <b>Jiahuan Zhou</b>, and Zheng Wang, "Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-Resolution", in Thirty-Seventh AAAI Conference on Artificial Intelligence, Washington, DC, USA, Feb. 2023, pp. 863-871, Doi: 10.1609/aaai.v37i1.25165
                                    <br>[<a href="pub/AAAI2023_Store.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{hu2023store,\n  title={Store and fetch immediately: Everything is all you need for space-time video super-resolution},\n  author={Hu, Mengshun and Jiang, Kui and Nie, Zhixiang and Zhou, Jiahuan and Wang, Zheng},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={37},\n  number={1},\n  pages={863--871},\n  year={2023}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>TPAMI'23</strong></i>)-<b>Jiahuan Zhou</b>, Bing Su, and Ying Wu, "Discriminative Self-Paced Group-Metric Adaptation for Online Visual Identification", in IEEE Transactions on Pattern Analysis & Machine Intelligence, vol. 45, no. 04, pp. 4368-4383, 2023. Doi: 10.1109/TPAMI.2022.3200036
                                    <br>[<a href="pub/TPAMI2023_SPGMA.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{zhou2022discriminative,\n  title={Discriminative self-paced group-metric adaptation for online visual identification},\n  author={Zhou, Jiahuan and Su, Bing and Wu, Ying},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n  volume={45},\n  number={4},\n  pages={4368--4383},\n  year={2022},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                




                                <li><p align="justify">(<i><strong>ECCV'22</strong></i>)-Mingfu Liang, <b>Jiahuan Zhou*</b>, Wei Wei, and Ying Wu, "Balancing between Forgetting and Acquisition in Incremental Subpopulation Learning", in Proc. European Conf. on Computer Vision, Tel-Aviv, Israel, Oct. 2022, pp. 364-380. Doi: 10.1007/978-3-031-19809-0_21
                                    <br>[<a href="pub/ECCV2022_ISL.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{liang2022balancing,\n  title={Balancing between forgetting and acquisition in incremental subpopulation learning},\n  author={Liang, Mingfu and Zhou, Jiahuan and Wei, Wei and Wu, Ying},\n  booktitle={European Conference on Computer Vision},\n  pages={364--380},\n  year={2022},\n  organization={Springer}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TPAMI'22</strong></i>)-Bing Su, <strong>Jiahuan Zhou*</strong>, Jirong Wen, and Ying Wu, "Linear and Deep Order-Preserving Wasserstein Discriminant Analysis", in IEEE Transactions on Pattern Analysis & Machine Intelligence, vol. 44, no. 06, pp. 3123-3138, 2022. Doi: 10.1109/TPAMI.2021.3050750
                                    <br>[<a href="pub/TPAMI2022_DeepOWDA.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{su2021linear,\n  title={Linear and deep order-preserving wasserstein discriminant analysis},\n  author={Su, Bing and Zhou, Jiahuan and Wen, Ji-Rong and Wu, Ying},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n  volume={44},\n  number={6},\n  pages={3123--3138},\n  year={2021},\n  publisher={IEEE}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR’20</strong></i>)-<b>Jiahuan Zhou</b>, Bing Su, and Ying Wu, "Online Joint Multi-Metric Adaptation From Frequent Sharing-Subset Mining for Person Re-Identification", in 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Seattle, WA, USA, 2020, pp. 2906-2915. Doi: 10.1109/CVPR42600.2020.00298
                                    <br>[<a href="pub/CVPR2020_M3.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zhou2020online,\n  title={Online joint multi-metric adaptation from frequent sharing-subset mining for person re-identification},\n  author={Zhou, Jiahuan and Su, Bing and Wu, Ying},\n  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},\n  pages={2909--2918},\n  year={2020}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR’20, Oral</strong></i>)-Yansong Tang#, Zanlin Ni#, <strong>Jiahuan Zhou</strong>, Danyang Zhang, Jiwen Lu, Ying Wu, and Jie Zhou, "Uncertainty-aware Score Distribution Learning for Action Quality Assessment", in 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle, WA, USA, 2020, pp. 9836-9845. Doi: 10.1109/CVPR42600.2020.00986
                                    <br>[<a href="pub/CVPR2020_MUSDL.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{tang2020uncertainty,\n  title={Uncertainty-aware score distribution learning for action quality assessment},\n  author={Tang, Yansong and Ni, Zanlin and Zhou, Jiahuan and Zhang, Danyang and Lu, Jiwen and Wu, Ying and Zhou, Jie},\n  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},\n  pages={9839--9848},\n  year={2020}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TPAMI’20</strong></i>)-<strong>Jiahuan Zhou</strong>, and Ying Wu, "Learning Visual Instance Retrieval from Failure: Efficient Online Local Metric Adaptation from Negative Samples", in IEEE Transactions on Pattern Analysis & Machine Intelligence, vol. 42, no. 11, pp. 2858-2873, 2020. Doi: 10.1109/TPAMI.2019.2918208
                                    <br>[<a href="pub/TPAMI2020_Failure.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{zhou2019learning,\n  title={Learning visual instance retrieval from failure: Efficient online local metric adaptation from negative samples},\n  author={Zhou, Jiahuan and Wu, Ying},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={42},\n  number={11},\n  pages={2858--2873},\n  year={2019},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICCV'19</strong></i>)-Bing Su, <strong>Jiahuan Zhou</strong>, and Ying Wu, "Order-preserving Wasserstein Discriminant Analysis", in 2019 IEEE/CVF International Conference on Computer Vision, Seoul, Korea (South), 2019, pp. 9884-9893. Doi: 10.1109/ICCV.2019.00998
                                    <br>[<a href="pub/ICCV2019_OWDA.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{su2019order,\n  title={Order-preserving wasserstein discriminant analysis},\n  author={Su, Bing and Zhou, Jiahuan and Wu, Ying},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={9885--9894},\n  year={2019}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICCV'19</strong></i>)-Xu Zou, Sheng Zhong, Luxin Yan, Xiangyun Zhao, <strong>Jiahuan Zhou</strong>*, and Ying Wu, "Learning Robust Facial Landmark Detection via Hierarchical Structured Ensemble", in 2019 IEEE/CVF International Conference on Computer Vision, Seoul, Korea (South), 2019, pp. 141-150. Doi: 10.1109/ICCV.2019.00023
                                    <br>[<a href="pub/ICCV2019_HSLE.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zou2019learning,\n  title={Learning robust facial landmark detection via hierarchical structured ensemble},\n  author={Zou, Xu and Zhong, Sheng and Yan, Luxin and Zhao, Xiangyun and Zhou, Jiahuan and Wu, Ying},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={141--150},\n  year={2019}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICIP'18</strong></i>)-Xinzhao Li, Yuehu Liu, Zeqi Chen, <strong>Jiahuan Zhou</strong>, and Ying Wu, "Fused Discriminative Metric Learning for Low Resolution Pedestrian Detection", in Proceedings of IEEE International Conference on Image Processing, Athens, Greece, Oct. 2018.
                                    <br>[<a href="pub/ICIP2018_PD.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{li2018fused,\n  title={Fused discriminative metric learning for low resolution pedestrian detection},\n  author={Li, Xinzhao and Liu, Yuehu and Chen, Zeqi and Zhou, Jiahuan and Wu, Ying},\n  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)},\n  pages={958--962},\n  year={2018},\n  organization={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'18</strong></i>)-<strong>Jiahuan Zhou</strong>, Bing Su, and Ying Wu, "Easy Identification from Better Constraints: Multi-Shot Person Re-Identification from Reference Constraints", in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 2018, pp. 5373-5381. Doi: 10.1109/CVPR.2018.00563
                                    <br>[<a href="pub/CVPR2018_Reference.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zhou2018easy,\n  title={Easy identification from better constraints: Multi-shot person re-identification from reference constraints},\n  author={Zhou, Jiahuan and Su, Bing and Wu, Ying},\n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={5373--5381},\n  year={2018}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICCV'17</strong></i>)-<strong>Jiahuan Zhou</strong>, Pei Yu, Tang Wei, and Ying Wu, "Efficient Online Local Metric Adaptation via Negative Samples for Person Re-Identification", in 2017 IEEE International Conference on Computer Vision, Venice, Italy, 2017, pp. 2439-2447. Doi: 10.1109/ICCV.2017.265
                                    <br>[<a href="pub/ICCV2017_OLMANS.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zhou2017efficient,\n  title={Efficient online local metric adaptation via negative samples for person re-identification},\n  author={Zhou, Jiahuan and Yu, Pei and Tang, Wei and Wu, Ying},\n  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n  pages={2420--2428},\n  year={2017}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICCV'17</strong></i>)-Wei Tang, Pei Yu, <strong>Jiahuan Zhou</strong>, and Ying Wu, "Towards a Unified Compositional Model for Visual Pattern Modeling", in 2017 IEEE International Conference on Computer Vision, Venice, Italy, 2017, pp. 2803-2812. Doi: 10.1109/ICCV.2017.303
                                    <br>[<a href="pub/ICCV2017_Compositional.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{tang2017towards,\n  title={Towards a unified compositional model for visual pattern modeling},\n  author={Tang, Wei and Yu, Pei and Zhou, Jiahuan and Wu, Ying},\n  booktitle={Proceedings of the IEEE international conference on computer vision},\n  pages={2784--2793},\n  year={2017}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TIP'17</strong></i>)-Bing Su, <strong>Jiahuan Zhou</strong>, Xiaoqing Ding, and Ying Wu, "Unsupervised Hierarchical Dynamic Parsing and Encoding for Action Recognition", in IEEE Transactions on Image Processing, 26.12: 5784-5799, Doi: 10.1109/TIP.2017.2745212
                                    <br>[<a href="pub/TIP2017_HDPE.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{su2017unsupervised,\n  title={Unsupervised hierarchical dynamic parsing and encoding for action recognition},\n  author={Su, Bing and Zhou, Jiahuan and Ding, Xiaoqing and Wu, Ying},\n  journal={IEEE Transactions on Image Processing},\n  volume={26},\n  number={12},\n  pages={5784--5799},\n  year={2017},\n  publisher={IEEE}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ECCV'16</strong></i>)-Bing Su, <strong>Jiahuan Zhou</strong>, Xiaoqing Ding, Hao Wang, and Ying Wu, "Hierarchical Dynamic Parsing and Encoding for Action Recognition", in Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part IV 14, pp. 202-217, Doi: 10.1007/978-3-319-46493-0_13
                                    <br>[<a href="pub/ECCV2016_HDPE.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{su2016hierarchical,\n  title={Hierarchical dynamic parsing and encoding for action recognition},\n  author={Su, Bing and Zhou, Jiahuan and Ding, Xiaoqing and Wang, Hao and Wu, Ying},\n  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV 14},\n  pages={202--217},\n  year={2016},\n  organization={Springer}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'16</strong></i>)-Pei Yu, <strong>Jiahuan Zhou</strong>, and Ying Wu, "Learning Reconstruction-based Remote Gaze Estimation", in 2016 IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA, 2016, pp. 3447-3455. Doi: 10.1109/CVPR.2016.375
                                    <br>[<a href="pub/CVPR2016_Gaze.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{yu2016learning,\n  title={Learning reconstruction-based remote gaze estimation},\n  author={Yu, Pei and Zhou, Jiahuan and Wu, Ying},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={3447--3455},\n  year={2016}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICIP'16, Oral</strong></i>)-<strong>Jiahuan Zhou*</strong>, and Ying Wu, "Finding the Right Exemplars for Reconstructing Single Image Super-Resolution", in 2016 IEEE International Conference on Image Processing, Phoenix, 2016, pp. 1414-1418
                                    <br>[<a href="pub/ICIP2016_SR.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zhou2016finding,\n  title={Finding the right exemplars for reconstructing single image super-resolution},\n  author={Zhou, Jiahuan and Wu, Ying},\n  booktitle={2016 IEEE International Conference on Image Processing (ICIP)},\n  pages={1414--1418},\n  year={2016},\n  organization={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICPR'12, Oral</strong></i>)-Han Hu, <strong>Jiahuan Zhou</strong>, Jianjiang Feng, and Jie Zhou, "Multi-way constrained spectral clustering by nonnegative restriction", in 2012 21st International Conference on Pattern Recognition, Tsukuba, 2012, pp. 1550-1553
                                    <br>[<a href="pub/ICPR2012_Clustering.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{hu2012multi,\n  title={Multi-way constrained spectral clustering by nonnegative restriction},\n  author={Hu, Han and Zhou, Jiahuan and Feng, Jianjiang and Zhou, Jie},\n  booktitle={Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)},\n  pages={1550--1553},\n  year={2012},\n  organization={IEEE}\n}')">bib</a>]
                                    </p>
                                </li>
                            </ol>
                        </div>

                        <div id="2025" class="paper-list">
                            <ol>
                                <li><p align="justify">(<i><strong>CVPR'25</strong></i>)-Zichen Liu, Kunlun Xu, Bing Su, Xu Zou, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding", in 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville TN, Jun.11 - Jun.15, 2025
                                    <br>[<a href="https://arxiv.org/abs/2503.15973">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/CVPR2025-STOP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@misc{liu2025stopintegratedspatialtemporaldynamic,title={STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding}, author={Zichen Liu and Kunlun Xu and Bing Su and Xu Zou and Yuxin Peng and Jiahuan Zhou},year={2025},eprint={2503.15973},archivePrefix={arXiv},primaryClass={cs.CV}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                </p>
                                </li>

                                <li><p align="justify">(<i><strong>CVPR'25</strong></i>)-Chenyu Zhang, Kunlun Xu, Zichen Liu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "SCAP: Transductive Test-Time Adaptation via Supportive Clique-based Attribute Prompting", in 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville TN, Jun.11 - Jun.15, 2025
                                    <br>[<a href=" https://arxiv.org/abs/2503.12866">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/CVPR2025-SCAP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{zhang2025scap,title={SCAP: Transductive Test-Time Adaptation via Supportive Clique-based Attribute Prompting},author={Zhang, Chenyu and Xu, Kunlun and Liu, Zichen and Peng, Yuxin and Zhou, Jiahuan},journal={arXiv preprint arXiv:2503.12866},year={2025}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'25</strong></i>)-Mingfu Liang, <b>Jiahuan Zhou*</b>, Xu Zou, and Ying Wu, "Incremental Object Keypoint Learning", in 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville TN, Jun.11 - Jun.15, 2025
                                    <br>[<a href="">pdf</a>] [<a href="">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'25</strong></i>)-Zhenyu Cui, <b>Jiahuan Zhou</b>, and Yuxin Peng, "DKC: Differentiated Knowledge Consolidation for Cloth-Hybrid Lifelong Person Re-identification", in 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville TN, Jun.11 - Jun.15, 2025
                                    <br>[<a href="">pdf</a>] [<a href="">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICLR'25</strong></i>)-Yanjie Wang, Liqun Chen, Tianming Zhao, Tao Zhang, Guodong Wang, Luxin Yan, Sheng Zhong, <b>Jiahuan Zhou*</b>, and Xu Zou*, "High-dimension Prototype is a Better Incremental Object Detection Learner", in the 13th International Conference on Learning Representations, Singapore, Apr.24 - Apr.28, 2025
                                    <br>[<a href="https://openreview.net/pdf?id=6T8czSBWce">pdf</a>] [<a href="">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>TIFS'25</strong></i>)-Xinyue Zhang, <b>Jiahuan Zhou</b>, Luxin Yan, Sheng Zhong, and Xu Zou, "Hunt Camouflaged Objects via Revealing Mutation Regions", in IEEE Transactions on Information Forensics and Security, 2025
                                    <br>[<a href="https://www.researchgate.net/publication/388091247_Hunt_Camouflaged_Objects_via_Revealing_Mutation_Regions">pdf</a>] [<a href="">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{article, author = {Zhang, Xinyue and Zhou, Jiahuan and Yan, Luxin and Zhong, Sheng and Zou, Xu}, year = {2025}, month = {01}, pages = {1-1}, title = {Hunt Camouflaged Objects via Revealing Mutation Regions}, volume = {PP}, journal = {IEEE Transactions on Information Forensics and Security}, doi = {10.1109/TIFS.2025.3530703}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'25</strong></i>)-Kunlun Xu, Chenghao Jiang, Peixi Xiong, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "DASK: Distribution Rehearsing via Adaptive Style Kernel Learning for Exemplar-Free Lifelong Person Re-Identification", in 39th Annual AAAI Conference on Artificial Intelligence, Philadelphia, Pennsylvania, USA, Feb.25 - Mar.4, 2025
                                    <br>[<a href="https://arxiv.org/pdf/2412.09224">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/AAAI2025-LReID-DASK">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{xu2024dask, title={DASK: Distribution Rehearsing via Adaptive Style Kernel Learning for Exemplar-Free Lifelong Person Re-Identification}, author={Xu, Kunlun and Jiang, Chenghao and Xiong, Peixi and Peng, Yuxin and Zhou, Jiahuan}, journal={arXiv preprint arXiv:2412.09224}, year={2024}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'25</strong></i>)-Yifeng Yao, Zichen Liu, Zhenyu Cui, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Selective Visual Prompting in Vision Mamba", in 39th Annual AAAI Conference on Artificial Intelligence, Philadelphia, Pennsylvania, USA, Feb.25 - Mar.4, 2025
                                    <br>[<a href="https://arxiv.org/pdf/2412.08947">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/AAAI2025-SVP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{yao2024selective, title={Selective Visual Prompting in Vision Mamba}, author={Yao, Yifeng and Liu, Zichen and Cui, Zhenyu and Peng, Yuxin and Zhou, Jiahuan}, journal={arXiv preprint arXiv:2412.08947}, year={2024}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'25</strong></i>)-Qiwei Li, and <b>Jiahuan Zhou*</b>, "CAPrompt: Cyclic Prompt Aggregation for Pre-Trained Model Based Class Incremental Learning", in 39th Annual AAAI Conference on Artificial Intelligence, Philadelphia, Pennsylvania, USA, Feb.25 - Mar.4, 2025
                                    <br>[<a href="https://arxiv.org/pdf/2412.08929">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/AAAI2025-CAPrompt">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{li2024caprompt, title={CAPrompt: Cyclic Prompt Aggregation for Pre-Trained Model Based Class Incremental Learning}, author={Li, Qiwei and Zhou, Jiahuan}, journal={arXiv preprint arXiv:2412.08929}, year={2024}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'25</strong></i>)-Yiyuan Liang, Liqun Chen, Zhiying Yan, <b>Jiahuan Zhou</b>, Luxin Yan, Sheng Zhong, and Xu Zou, "DriveEditor: 3D Information Guided Controllable Object Editing in Driving Scene", in 39th Annual AAAI Conference on Artificial Intelligence, Philadelphia, Pennsylvania, USA, Feb.25 - Mar.4, 2025
                                    <br>[<a href="https://arxiv.org/pdf/2412.19458">pdf</a>] [<a href="https://github.com/yvanliang/DriveEditor">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{liang2024driveeditor, title={DriveEditor: A Unified 3D Information-Guided Framework for Controllable Object Editing in Driving Scenes}, author={Liang, Yiyuan and Yan, Zhiying and Chen, Liqun and Zhou, Jiahuan and Yan, Luxin and Zhong, Sheng and Zou, Xu}, journal={arXiv preprint arXiv:2412.19458}, year={2024}}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                            </ol>
                        </div>
                        
                        <div id="2024" class="paper-list">
                            <ol>
                                <li><p align="justify">(<i><strong>Nat. Commun'24</strong></i>)-Ziyi Han, Shengqiang Wu, Chun Huang, Fengyuan Xuan, Xiaocang Han, Yinfeng Long, Qing Zhang, Junxian Li, Yuan Meng, Lin Wang, <b>Jiahuan Zhou</b>, Wenping Hu, Jingsi Qiao, Dechao Geng, and Xiaoxu Zhao, "Atomically engineering interlayer symmetry operations of two-dimensional crystals", in Nature Communications, 2024, vol. 15, no. 1, pp. 10835, Doi: 10.1038/s41467-024-55130-z
                                    <br>[<a href="https://www.nature.com/articles/s41467-024-55130-z.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{han2024atomically, title={Atomically engineering interlayer symmetry operations of two-dimensional crystals}, author={Han, Ziyi and Wu, Shengqiang and Huang, Chun and Xuan, Fengyuan and Han, Xiaocang and Long, Yinfeng and Zhang, Qing and Li, Junxian and Meng, Yuan and Wang, Lin and others}, journal={Nature Communications}, volume={15}, number={1}, pages={10835}, year={2024}, publisher={Nature Publishing Group UK London}}')">bib</a>]
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ACM MM'24</strong></i>)-Qiwei Li, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Progressive Prototype Evolving for Dual-Forgetting Mitigation in Non-Exemplar Online Continual Learning", in 32nd ACM Multimedia Conference, Melbourne, Australia, 2024
                                    <br>[<a href="pub/2024 ACM MM Progressive Prototype Evolving for Dual-Forgetting Mitigation in Non-Exemplar Online Continual Learning.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/MM2024-PPE">code</a>] [<a href="#" onclick="copyTextAndNotify(event, 'This bib is currently unavaliable')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ACM MM'24</strong></i>)-Kunlun Xu, Haozhuo Zhang, Yu Li, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Mitigate Catastrophic Remembering via Continual Knowledge Purification for Noisy Lifelong Person Re-Identification", in 32nd ACM Multimedia Conference, Melbourne, Australia, 2024
                                    <br>[<a href="pub/2024 ACM MM Mitigate Catastrophic Remembering via Continual Knowledge Purification for Noisy Lifelong Person Re-Identification.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/MM2024-CKP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, 'This bib is currently unavaliable')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(200, 200, 255);"></span>
                                        <span class="tag">NL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ACM MM'24</strong></i>)-Zichen Liu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "InsVP: Efficient Instance Visual Prompting from Image Itself", in 32nd ACM Multimedia Conference, Melbourne, Australia, 2024
                                    <br>[<a href="pub/2024 ACM MM InsVP  Efficient Instance Visual Prompting from Image Itself.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/MM2024-InsVP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, 'This bib is currently unavaliable')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ACM MM'24</strong></i>)-Qiwen Zhu, Yanjie Wang, Shilv Cai, Liqun Chen, <b>Jiahuan Zhou</b>, Luxin Yan, Sheng Zhong, and Xu Zou, "Perceptual-Distortion Balanced Image Super-Resolution is a Multi-Objective Optimization Problem", in 32nd ACM Multimedia Conference, Melbourne, Australia, 2024
                                    <br>[<a href="pub/2024 ACM MM Perceptual-Distortion Balanced Image Super-Resolution is a Multi-Objective Optimization Problem.pdf">pdf</a>] [<a href="https://github.com/ZhuKeven/MOBOSR">code</a>] [<a href="#" onclick="copyTextAndNotify(event, 'This bib is currently unavaliable')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>IJCV'24</strong></i>)-Zichen Liu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Compositional Prompting for Anti-Forgetting in Domain Incremental Learning", in International Journal of Computer Vision, 2024, pp. 1-18, Doi: 10.1007/s11263-024-02134-3
                                    <br>[<a href="pub/2024 IJCV Compositional Prompting for Anti-Forgetting in Domain Incremental Learning.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/IJCV2024-C-Prompt">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{liu2024compositional,\n  title={Compositional Prompting for Anti-Forgetting in Domain Incremental Learning},\n  author={Liu, Zichen and Peng, Yuxin and Zhou, Jiahuan},\n  journal={International Journal of Computer Vision},\n  pages={1--18},\n  year={2024},\n  publisher={Springer}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>IJCV'24</strong></i>)-Qiwei Li, Kunlun Xu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Exemplar-Free Lifelong Person Re-Identification via Prompt-guided Adaptive Knowledge Consolidation", in International Journal of Computer Vision, 2024, pp. 1-16, Doi: 10.1007/s11263-024-02110-x
                                    <br>[<a href="pub/2024 IJCV Exemplar-Free Lifelong Person Re-Identification via Prompt-guided Adaptive Knowledge Consolidation.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/IJCV2024-PAEMA/">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{li2024exemplar,\n  title={Exemplar-Free Lifelong Person Re-identification via Prompt-Guided Adaptive Knowledge Consolidation},\n  author={Li, Qiwei and Xu, Kunlun and Peng, Yuxin and Zhou, Jiahuan},\n  journal={International Journal of Computer Vision},\n  pages={1--16},\n  year={2024},\n  publisher={Springer}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>IJCAI'24</strong></i>)-Hongbo Sun, <b>Jiahuan Zhou</b>, Xiangteng He, Jinglin Xu, and Yuxin Peng, "FineFMPL: Fine-grained Feature Mining Prompt Learning for Few-Shot Class Incremental Learning", in 2024 International Joint Conference on Artificial Intelligence, Jeju, South Korea, 2024
                                    <br>[<a href="pub/IJCAI2024_FineFMPL.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{sunfinefmpl,\n  title={FineFMPL: Fine-grained Feature Mining Prompt Learning for Few-Shot Class Incremental Learning},\n  author={Sun, Hongbo and Zhou, Jiahuan and He, Xiangteng and Xu, Jinglin and Peng, Yuxin}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 80, 80);"></span>
                                        <span class="tag">FR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(0, 0, 255);"></span>
                                        <span class="tag">Z/F L &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>Nat. Synth'24</strong></i>)-Xiaocang Han, Mengmeng Niu, Yan Luo, Runlai Li, Jiadong Dan, Yanhui Hong, Xu Wu, Alex V. Trukhanov, Wei Ji, Yeliang Wang, <b>Jiahuan Zhou</b>, Jingsi Qiao, Jin Zhang, and Xiaoxu Zhao, "Atomically engineering metal vacancies in monolayer transition metal dichalcogenides" in Nature Synthesis, 2024, Doi: 10.1038/s44160-024-00501-z
                                    <br>[<a href="pub/2024 Nature Synthesis Atomically engineering metal vacancies in monolayer transition metal dichalcogenides.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{han2024atomically,\n  title={Atomically engineering metal vacancies in monolayer transition metal dichalcogenides},\n  author={Han, Xiaocang and Niu, Mengmeng and Luo, Yan and Li, Runlai and Dan, Jiadong and Hong, Yanhui and Wu, Xu and Trukhanov, Alex V and Ji, Wei and Wang, Yeliang and others},\n  journal={Nature Synthesis},\n  volume={3},\n  number={5},\n  pages={586--594},\n  year={2024},\n  publisher={Nature Publishing Group UK London}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'24</strong></i>)-Kunlun Xu, Xu Zou, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Distribution-aware Knowledge Prototyping for Non-exemplar Lifelong Person Re-identification", in 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle WA, USA, 2024, pp. 16604-16613
                                    <br>[<a href="pub/CVPR2024_DKP.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/CVPR2024-DKP">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{xu2024distribution,\n  title={Distribution-aware Knowledge Prototyping for Non-exemplar Lifelong Person Re-identification},\n  author={Xu, Kunlun and Zou, Xu and Peng, Yuxin and Zhou, Jiahuan},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={16604--16613},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'24</strong></i>)-Qiwei Li, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "FCS: Feature Calibration and Separation for Non-Exemplar Class Incremental Learning", in 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle WA, USA, 2024, pp. 28495-28504
                                    <br>[<a href="pub/CVPR2024_FCS.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/CVPR2024-FCS">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{li2024fcs,\n  title={FCS: Feature Calibration and Separation for Non-Exemplar Class Incremental Learning},\n  author={Li, Qiwei and Peng, Yuxin and Zhou, Jiahuan},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={28495--28504},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'24</strong></i>)-Yanjie Wang, Xu Zou, Luxin Yan, Sheng Zhong, and <b>Jiahuan Zhou</b>, "SNIDA: Unlocking Few-Shot object Detection with Non-linear Semantic Decoupling Augmentation", in 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle WA, USA, 2024, pp. 12544-12553
                                    <br>[<a href="pub/CVPR2024_SNIDA.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{wang2024snida,\n  title={SNIDA: Unlocking Few-Shot Object Detection with Non-linear Semantic Decoupling Augmentation},\n  author={Wang, Yanjie and Zou, Xu and Yan, Luxin and Zhong, Sheng and Zhou, Jiahuan},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={12544--12553},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(0, 0, 255);"></span>
                                        <span class="tag">Z/F L &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'24</strong></i>)-Zhenyu Cui, <b>Jiahuan Zhou</b>, Xun Wang, Manyu Zhu, and Yuxin Peng, "Learning Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification", in 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle WA, USA, 2024, pp. 16614-16623
                                    <br>[<a href="pub/CVPR2024_C2R.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/C2R_CVPR2024">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{cui2024learning,\n  title={Learning Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification},\n  author={Cui, Zhenyu and Zhou, Jiahuan and Wang, Xun and Zhu, Manyu and Peng, Yuxin},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={16614--16623},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TPAMI'24</strong></i>)-Shilv Cai, Liqun Chen, Zhijun Zhang, Xiangyun Zhao, and <b>Jiahuan Zhou</b>, Yuxin Peng, Luxin Yan, Sheng Zhong, and Xu Zou, "I2C: Invertible Continuous Codec for High-Fidelity Variable-Rate Image Compression", in IEEE Transactions on Pattern Analysis & Machine Intelligence, 2024, vol. 46, no. 6, pp. 4262-4279, Doi: 10.1109/TPAMI.2024.3356557
                                    <br>[<a href="pub/TPAMI2024_I2C.pdf">pdf</a>] [<a href="https://github.com/CaiShilv/HiFi-VRIC">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{cai2024i2c,\n  title={I2C: Invertible Continuous Codec for High-Fidelity Variable-Rate Image Compression},\n  author={Cai, Shilv and Chen, Liqun and Zhang, Zhijun and Zhao, Xiangyun and Zhou, Jiahuan and Peng, Yuxin and Yan, Luxin and Zhong, Sheng and Zou, Xu},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n  year={2024},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TOMM'24</strong></i>)-Yanzhe Chen, <b>Jiahuan Zhou</b>, and Yuxin Peng, "SPIRIT: Style-guided Patch Interaction for Fashion Image Retrieval with Text Feedback", in ACM Transactions on Multimedia Computing, Communications, and Applications, 2024, pp. 1-17, Doi: 10.1145/3640345
                                    <br>[<a href="pub/2024 ToMM SPIRIT  Style-guided Patch Interaction for Fashion Image Retrieval with Text Feedback.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/SPIRIT_TOMM2024">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{chen2024spirit,\n  title={SPIRIT: Style-guided Patch Interaction for Fashion Image Retrieval with Text Feedback},\n  author={Chen, Yanzhe and Zhou, Jiahuan and Peng, Yuxin},\n  journal={ACM Transactions on Multimedia Computing, Communications and Applications},\n  volume={20},\n  number={6},\n  pages={1--17},\n  year={2024},\n  publisher={ACM New York, NY}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 50, 0);"></span>
                                        <span class="tag">V&L &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Kunlun Xu, Xu Zou, and <b>Jiahuan Zhou*</b>, "LSTKC: Long Short-Term Knowledge Consolidation for Lifelong Person Re-Identification", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, vol. 38, no. 14, pp. 16202-16210, Doi: 10.1609/aaai.v38i14.29554
                                    <br>[<a href="pub/AAAI2024_LSTK.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/LSTKC">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{xu2024lstkc,\n  title={LSTKC: Long Short-Term Knowledge Consolidation for Lifelong Person Re-identification},\n  author={Xu, Kunlun and Zou, Xu and Zhou, Jiahuan},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={14},\n  pages={16202--16210},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Zichen Liu, Hongbo Sun, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "DART: Dual-Modal Adaptive Online Prompting and Knowledge Retention for Test-Time Adaptation", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, Vol. 38, No. 14, pp. 16202-16210, Doi: 10.1609/aaai.v38i14.29554
                                    <br>[<a href="pub/AAAI2024_DART.pdf">pdf</a>] [<a href="https://github.com/zhoujiahuan1991/DART">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{liu2024dart,\n  title={DART: Dual-Modal Adaptive Online Prompting and Knowledge Retention for Test-Time Adaptation},\n  author={Liu, Zichen and Sun, Hongbo and Peng, Yuxin and Zhou, Jiahuan},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={13},\n  pages={14106--14114},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Zhenyu Cui, Yuxin Peng, Xun Wang, Manyu Zhu, and <b>Jiahuan Zhou</b>, "Continual Vision-Language Retrieval via Dynamic Knowledge Rectification", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, Vol. 38, No. 10, pp. 11704-11712, Doi: 10.1609/aaai.v38i10.29054
                                    <br>[<a href="pub/AAAI2024_CVLR.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{cui2024continual,\n  title={Continual Vision-Language Retrieval via Dynamic Knowledge Rectification},\n  author={Cui, Zhenyu and Peng, Yuxin and Wang, Xun and Zhu, Manyu and Zhou, Jiahuan},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={10},\n  pages={11704--11712},\n  year={2024}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 50, 0);"></span>
                                        <span class="tag">V&L &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Yanzhe Chen, Huasong Zhong, Xiangteng He, Yuxin Peng, <b>Jiahuan Zhou</b>, and Lele Cheng, "FashionERN: Enhance-and-Refine Network for Composed Fashion Image Retrieval", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, Vol. 38, No. 2, pp. 1228-1236, Doi:10.1609/aaai.v38i2.27885
                                    <br>[<a href="pub/AAAI2024_FASHIONERN.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{chen2024fashionern,\n  title={FashionERN: Enhance-and-Refine Network for Composed Fashion Image Retrieval},\n  author={Chen, Yanzhe and Zhong, Huasong and He, Xiangteng and Peng, Yuxin and Zhou, Jiahuan and Cheng, Lele},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={2},\n  pages={1228--1236},\n  year={2024}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'24</strong></i>)-Shilv Cai, Liqun Chen, Sheng Zhong, Luxin Yan, <b>Jiahuan Zhou</b>, and Xu Zou, "Make Lossy Compression Meaningful for Low-light Images", in Thirty-Eighth AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2024, Vol. 38, No. 8, pp. 8236-8245, Doi: 10.1609/aaai.v38i8.28664
                                    <br>[<a href="pub/AAAI2024_MAKE.pdf">pdf</a>] [<a href="https://github.com/CaiShilv/Joint-IC-LL">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{cai2024make,\n  title={Make Lossy Compression Meaningful for Low-Light Images},\n  author={Cai, Shilv and Chen, Liqun and Zhong, Sheng and Yan, Luxin and Zhou, Jiahuan and Zou, Xu},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={38},\n  number={8},\n  pages={8236--8245},\n  year={2024}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TIFS'24</strong></i>)-Zhenyu Cui, <b>Jiahuan Zhou</b>, and Yuxin Peng, "DMA: Dual Modality-Aware Alignment for Visible-Infrared Person Re-Identification", in IEEE Transactions on Information Forensics and Security, 2024, Vol. 19, pp. 2696-2708, doi: 10.1109/TIFS.2024.3352408
                                    <br>[<a href="pub/TIFS2023_DMA.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/DMA_TIFS2023">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{cui2024dma,\n  title={DMA: Dual Modality-Aware Alignment for Visible-Infrared Person Re-Identification},\n  author={Cui, Zhenyu and Zhou, Jiahuan and Peng, Yuxin},\n  journal={IEEE Transactions on Information Forensics and Security},\n  year={2024},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(200, 150, 0);"></span>
                                        <span class="tag">V2T &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>计算机科学'24</strong></i>)-崔振宇, <b>周嘉欢</b>, 彭宇新, "跨模态目标重识别研究综述", 计算机科学 (创刊50周年特别专题综述论文), 2024, Vol. 51, No.1, pp. 13-25.
                                    <br>[<a href="https://www.jsjkx.com/CN/10.11896/jsjkx.yg20240103">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{cui2024cross,\n  title={跨模态目标重识别研究综述},\n  author={Cui, Zhenyu and Zhou, Jiahuan and Peng, Yuxin},\n  journal={计算机科学},\n  volume={51},\n  number={1},\n  pages={13--25},\n  year={2024},\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(200, 150, 0);"></span>
                                        <span class="tag">V2T &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                            </ol>
                        </div>

                        <div id="2023" class="paper-list">
                            <ol>
                                <li><p align="justify">(<i><strong>ACM MM'23</strong></i>)-Hongbo Sun, Xiangteng He, <b>Jiahuan Zhou</b>, and Yuxin Peng, "Fine-Grained Visual Prompt Learning of Vision-Language Models for Image Recognition", in 31st ACM Multimedia Conference, Ottawa, Canada, Oct.29 - Nov.3, 2023, pp. 5828-5836, Doi: 10.1145/3581783.3612403
                                    <br>[<a href="pub/MM2023_Finegrained.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{sun2023fine,\n  title={Fine-grained visual prompt learning of vision-language models for image recognition},\n  author={Sun, Hongbo and He, Xiangteng and Zhou, Jiahuan and Peng, Yuxin},\n  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},\n  pages={5828--5836},\n  year={2023}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 80, 80);"></span>
                                        <span class="tag">FR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 100, 255);"></span>
                                        <span class="tag">PL &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(100, 50, 0);"></span>
                                        <span class="tag">V&L &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICIG'23</strong></i>)-Kunlun Xu, Yuxin Peng, and <b>Jiahuan Zhou*</b>, "Uncover the Body: Occluded Person Re-identification via Masked Image Modeling", in 12rd International Conference on Image and Graphics, Nanjing, China, Sep.22 - 24, 2023, pp. 241-253, Doi: 10.1007/978-3-031-46305-1_20
                                    <br>[<a href="pub/ICIG2023_Uncover.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{xu2023uncover,\n  title={Uncover the Body: Occluded Person Re-identification via Masked Image Modeling},\n  author={Xu, Kunlun and Peng, Yuxin and Zhou, Jiahuan},\n  booktitle={International Conference on Image and Graphics},\n  pages={241--253},\n  year={2023},\n  organization={Springer}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>TCSVT'23</strong></i>)-Zeqi Chen, Zhichao Cui, Chi Zhang, <b>Jiahuan Zhou</b>, and Yuehu Liu, "Dual Clustering Co-teaching with Consistent Sample Mining for Unsupervised Person Re-Identification", in IEEE Transactions on Circuits and Systems for Video Technology, 2023, vol. 33, no. 10, pp. 5908-5920, Doi: 10.1109/TCSVT.2023.3261898
                                    <br>[<a href="pub/TCSVT2023_Dual.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{chen2023dual,\n  title={Dual clustering co-teaching with consistent sample mining for unsupervised person re-identification},\n  author={Chen, Zeqi and Cui, Zhichao and Zhang, Chi and Zhou, Jiahuan and Liu, Yuehu},\n  journal={IEEE Transactions on Circuits and Systems for Video Technology},\n  volume={33},\n  number={10},\n  pages={5908--5920},\n  year={2023},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>TCSVT'23</strong></i>)-Zhenyu Cui, <b>Jiahuan Zhou</b>, Yuxin Peng, Shiliang Zhang, and Yaowei Wang, "DCR-ReID: Deep Component Reconstruction for Cloth-Changing Person Re-Identification", in IEEE Transactions on Circuits and Systems for Video Technology, 2023, vol. 33, no. 8, pp. 4415-4428, Doi: 10.1109/TCSVT.2023.3241988
                                    <br>[<a href="pub/TCSVT2023_DCR.pdf">pdf</a>] [<a href="https://github.com/PKU-ICST-MIPL/DCR-ReID_TCSVT2023">code</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{cui2023dcr,\n  title={Dcr-reid: Deep component reconstruction for cloth-changing person re-identification},\n  author={Cui, Zhenyu and Zhou, Jiahuan and Peng, Yuxin and Zhang, Shiliang and Wang, Yaowei},\n  journal={IEEE Transactions on Circuits and Systems for Video Technology},\n  volume={33},\n  number={8},\n  pages={4415--4428},\n  year={2023},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>AAAI'23</strong></i>)-MengShun Hu, Kui Jiang, Zhixiang Nie, <b>Jiahuan Zhou</b>, and Zheng Wang, "Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-Resolution", in Thirty-Seventh AAAI Conference on Artificial Intelligence, Washington, DC, USA, Feb. 2023, pp. 863-871, Doi: 10.1609/aaai.v37i1.25165
                                    <br>[<a href="pub/AAAI2023_Store.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{hu2023store,\n  title={Store and fetch immediately: Everything is all you need for space-time video super-resolution},\n  author={Hu, Mengshun and Jiang, Kui and Nie, Zhixiang and Zhou, Jiahuan and Wang, Zheng},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={37},\n  number={1},\n  pages={863--871},\n  year={2023}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>TPAMI'23</strong></i>)-<b>Jiahuan Zhou</b>, Bing Su, and Ying Wu, "Discriminative Self-Paced Group-Metric Adaptation for Online Visual Identification", in IEEE Transactions on Pattern Analysis & Machine Intelligence, vol. 45, no. 04, pp. 4368-4383, 2023. Doi: 10.1109/TPAMI.2022.3200036
                                    <br>[<a href="pub/TPAMI2023_SPGMA.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{zhou2022discriminative,\n  title={Discriminative self-paced group-metric adaptation for online visual identification},\n  author={Zhou, Jiahuan and Su, Bing and Wu, Ying},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n  volume={45},\n  number={4},\n  pages={4368--4383},\n  year={2022},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                
                            </ol>
                        </div>
                    
                        <div id="2022" class="paper-list">
                            <ol>
                                <li><p align="justify">(<i><strong>ECCV'22</strong></i>)-Mingfu Liang, <b>Jiahuan Zhou*</b>, Wei Wei, and Ying Wu, "Balancing between Forgetting and Acquisition in Incremental Subpopulation Learning", in Proc. European Conf. on Computer Vision, Tel-Aviv, Israel, Oct. 2022, pp. 364-380. Doi: 10.1007/978-3-031-19809-0_21
                                    <br>[<a href="pub/ECCV2022_ISL.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{liang2022balancing,\n  title={Balancing between forgetting and acquisition in incremental subpopulation learning},\n  author={Liang, Mingfu and Zhou, Jiahuan and Wei, Wei and Wu, Ying},\n  booktitle={European Conference on Computer Vision},\n  pages={364--380},\n  year={2022},\n  organization={Springer}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(50, 50, 255);"></span>
                                        <span class="tag">IL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TPAMI'22</strong></i>)-Bing Su, <strong>Jiahuan Zhou*</strong>, Jirong Wen, and Ying Wu, "Linear and Deep Order-Preserving Wasserstein Discriminant Analysis", in IEEE Transactions on Pattern Analysis & Machine Intelligence, vol. 44, no. 06, pp. 3123-3138, 2022. Doi: 10.1109/TPAMI.2021.3050750
                                    <br>[<a href="pub/TPAMI2022_DeepOWDA.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{su2021linear,\n  title={Linear and deep order-preserving wasserstein discriminant analysis},\n  author={Su, Bing and Zhou, Jiahuan and Wen, Ji-Rong and Wu, Ying},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n  volume={44},\n  number={6},\n  pages={3123--3138},\n  year={2021},\n  publisher={IEEE}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR’20</strong></i>)-<b>Jiahuan Zhou</b>, Bing Su, and Ying Wu, "Online Joint Multi-Metric Adaptation From Frequent Sharing-Subset Mining for Person Re-Identification", in 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Seattle, WA, USA, 2020, pp. 2906-2915. Doi: 10.1109/CVPR42600.2020.00298
                                    <br>[<a href="pub/CVPR2020_M3.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zhou2020online,\n  title={Online joint multi-metric adaptation from frequent sharing-subset mining for person re-identification},\n  author={Zhou, Jiahuan and Su, Bing and Wu, Ying},\n  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},\n  pages={2909--2918},\n  year={2020}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR’20, Oral</strong></i>)-Yansong Tang#, Zanlin Ni#, <strong>Jiahuan Zhou</strong>, Danyang Zhang, Jiwen Lu, Ying Wu, and Jie Zhou, "Uncertainty-aware Score Distribution Learning for Action Quality Assessment", in 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle, WA, USA, 2020, pp. 9836-9845. Doi: 10.1109/CVPR42600.2020.00986
                                    <br>[<a href="pub/CVPR2020_MUSDL.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{tang2020uncertainty,\n  title={Uncertainty-aware score distribution learning for action quality assessment},\n  author={Tang, Yansong and Ni, Zanlin and Zhou, Jiahuan and Zhang, Danyang and Lu, Jiwen and Wu, Ying and Zhou, Jie},\n  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},\n  pages={9839--9848},\n  year={2020}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TPAMI’20</strong></i>)-<strong>Jiahuan Zhou</strong>, and Ying Wu, "Learning Visual Instance Retrieval from Failure: Efficient Online Local Metric Adaptation from Negative Samples", in IEEE Transactions on Pattern Analysis & Machine Intelligence, vol. 42, no. 11, pp. 2858-2873, 2020. Doi: 10.1109/TPAMI.2019.2918208
                                    <br>[<a href="pub/TPAMI2020_Failure.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{zhou2019learning,\n  title={Learning visual instance retrieval from failure: Efficient online local metric adaptation from negative samples},\n  author={Zhou, Jiahuan and Wu, Ying},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={42},\n  number={11},\n  pages={2858--2873},\n  year={2019},\n  publisher={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICCV'19</strong></i>)-Bing Su, <strong>Jiahuan Zhou</strong>, and Ying Wu, "Order-preserving Wasserstein Discriminant Analysis", in 2019 IEEE/CVF International Conference on Computer Vision, Seoul, Korea (South), 2019, pp. 9884-9893. Doi: 10.1109/ICCV.2019.00998
                                    <br>[<a href="pub/ICCV2019_OWDA.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{su2019order,\n  title={Order-preserving wasserstein discriminant analysis},\n  author={Su, Bing and Zhou, Jiahuan and Wu, Ying},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={9885--9894},\n  year={2019}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICCV'19</strong></i>)-Xu Zou, Sheng Zhong, Luxin Yan, Xiangyun Zhao, <strong>Jiahuan Zhou</strong>*, and Ying Wu, "Learning Robust Facial Landmark Detection via Hierarchical Structured Ensemble", in 2019 IEEE/CVF International Conference on Computer Vision, Seoul, Korea (South), 2019, pp. 141-150. Doi: 10.1109/ICCV.2019.00023
                                    <br>[<a href="pub/ICCV2019_HSLE.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zou2019learning,\n  title={Learning robust facial landmark detection via hierarchical structured ensemble},\n  author={Zou, Xu and Zhong, Sheng and Yan, Luxin and Zhao, Xiangyun and Zhou, Jiahuan and Wu, Ying},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={141--150},\n  year={2019}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICIP'18</strong></i>)-Xinzhao Li, Yuehu Liu, Zeqi Chen, <strong>Jiahuan Zhou</strong>, and Ying Wu, "Fused Discriminative Metric Learning for Low Resolution Pedestrian Detection", in Proceedings of IEEE International Conference on Image Processing, Athens, Greece, Oct. 2018.
                                    <br>[<a href="pub/ICIP2018_PD.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{li2018fused,\n  title={Fused discriminative metric learning for low resolution pedestrian detection},\n  author={Li, Xinzhao and Liu, Yuehu and Chen, Zeqi and Zhou, Jiahuan and Wu, Ying},\n  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)},\n  pages={958--962},\n  year={2018},\n  organization={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 150, 150);"></span>
                                        <span class="tag">OD &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'18</strong></i>)-<strong>Jiahuan Zhou</strong>, Bing Su, and Ying Wu, "Easy Identification from Better Constraints: Multi-Shot Person Re-Identification from Reference Constraints", in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 2018, pp. 5373-5381. Doi: 10.1109/CVPR.2018.00563
                                    <br>[<a href="pub/CVPR2018_Reference.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zhou2018easy,\n  title={Easy identification from better constraints: Multi-shot person re-identification from reference constraints},\n  author={Zhou, Jiahuan and Su, Bing and Wu, Ying},\n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={5373--5381},\n  year={2018}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICCV'17</strong></i>)-<strong>Jiahuan Zhou</strong>, Pei Yu, Tang Wei, and Ying Wu, "Efficient Online Local Metric Adaptation via Negative Samples for Person Re-Identification", in 2017 IEEE International Conference on Computer Vision, Venice, Italy, 2017, pp. 2439-2447. Doi: 10.1109/ICCV.2017.265
                                    <br>[<a href="pub/ICCV2017_OLMANS.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zhou2017efficient,\n  title={Efficient online local metric adaptation via negative samples for person re-identification},\n  author={Zhou, Jiahuan and Yu, Pei and Tang, Wei and Wu, Ying},\n  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n  pages={2420--2428},\n  year={2017}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 0, 0);"></span>
                                        <span class="tag">OR &nbsp;</span>
                                    </span>
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(150, 150, 255);"></span>
                                        <span class="tag">OL &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICCV'17</strong></i>)-Wei Tang, Pei Yu, <strong>Jiahuan Zhou</strong>, and Ying Wu, "Towards a Unified Compositional Model for Visual Pattern Modeling", in 2017 IEEE International Conference on Computer Vision, Venice, Italy, 2017, pp. 2803-2812. Doi: 10.1109/ICCV.2017.303
                                    <br>[<a href="pub/ICCV2017_Compositional.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{tang2017towards,\n  title={Towards a unified compositional model for visual pattern modeling},\n  author={Tang, Wei and Yu, Pei and Zhou, Jiahuan and Wu, Ying},\n  booktitle={Proceedings of the IEEE international conference on computer vision},\n  pages={2784--2793},\n  year={2017}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>TIP'17</strong></i>)-Bing Su, <strong>Jiahuan Zhou</strong>, Xiaoqing Ding, and Ying Wu, "Unsupervised Hierarchical Dynamic Parsing and Encoding for Action Recognition", in IEEE Transactions on Image Processing, 26.12: 5784-5799, Doi: 10.1109/TIP.2017.2745212
                                    <br>[<a href="pub/TIP2017_HDPE.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@article{su2017unsupervised,\n  title={Unsupervised hierarchical dynamic parsing and encoding for action recognition},\n  author={Su, Bing and Zhou, Jiahuan and Ding, Xiaoqing and Wu, Ying},\n  journal={IEEE Transactions on Image Processing},\n  volume={26},\n  number={12},\n  pages={5784--5799},\n  year={2017},\n  publisher={IEEE}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ECCV'16</strong></i>)-Bing Su, <strong>Jiahuan Zhou</strong>, Xiaoqing Ding, Hao Wang, and Ying Wu, "Hierarchical Dynamic Parsing and Encoding for Action Recognition", in Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part IV 14, pp. 202-217, Doi: 10.1007/978-3-319-46493-0_13
                                    <br>[<a href="pub/ECCV2016_HDPE.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{su2016hierarchical,\n  title={Hierarchical dynamic parsing and encoding for action recognition},\n  author={Su, Bing and Zhou, Jiahuan and Ding, Xiaoqing and Wang, Hao and Wu, Ying},\n  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV 14},\n  pages={202--217},\n  year={2016},\n  organization={Springer}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>CVPR'16</strong></i>)-Pei Yu, <strong>Jiahuan Zhou</strong>, and Ying Wu, "Learning Reconstruction-based Remote Gaze Estimation", in 2016 IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA, 2016, pp. 3447-3455. Doi: 10.1109/CVPR.2016.375
                                    <br>[<a href="pub/CVPR2016_Gaze.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{yu2016learning,\n  title={Learning reconstruction-based remote gaze estimation},\n  author={Yu, Pei and Zhou, Jiahuan and Wu, Ying},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={3447--3455},\n  year={2016}\n}')">bib</a>]
                                    </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICIP'16, Oral</strong></i>)-<strong>Jiahuan Zhou*</strong>, and Ying Wu, "Finding the Right Exemplars for Reconstructing Single Image Super-Resolution", in 2016 IEEE International Conference on Image Processing, Phoenix, 2016, pp. 1414-1418
                                    <br>[<a href="pub/ICIP2016_SR.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{zhou2016finding,\n  title={Finding the right exemplars for reconstructing single image super-resolution},\n  author={Zhou, Jiahuan and Wu, Ying},\n  booktitle={2016 IEEE International Conference on Image Processing (ICIP)},\n  pages={1414--1418},\n  year={2016},\n  organization={IEEE}\n}')">bib</a>]
                                    <span class="tag-container">
                                        <span class="number-box" style="background-color: rgb(255, 224, 224);"></span>
                                        <span class="tag">AIGC &nbsp;</span>
                                    </span>
                                </p>
                                </li>
                                <li><p align="justify">(<i><strong>ICPR'12, Oral</strong></i>)-Han Hu, <strong>Jiahuan Zhou</strong>, Jianjiang Feng, and Jie Zhou, "Multi-way constrained spectral clustering by nonnegative restriction", in 2012 21st International Conference on Pattern Recognition, Tsukuba, 2012, pp. 1550-1553
                                    <br>[<a href="pub/ICPR2012_Clustering.pdf">pdf</a>] [<a href="#" onclick="copyTextAndNotify(event, '@inproceedings{hu2012multi,\n  title={Multi-way constrained spectral clustering by nonnegative restriction},\n  author={Hu, Han and Zhou, Jiahuan and Feng, Jianjiang and Zhou, Jie},\n  booktitle={Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)},\n  pages={1550--1553},\n  year={2012},\n  organization={IEEE}\n}')">bib</a>]
                                    </p>
                                </li>
                            </ol>
                        </div>

                        <p><b>Note</b>: * indicates the corresponding author; # indicates equal contribution.</p>
                        <p><a href="https://scholar.google.com/citations?user=ZLZmI8sAAAAJ&hl=en&oi=ao">Full list of publications in Google Scholar.</a></p>

                    </section>
                    <p id="services" style="height:4rem;margin: 0;">&nbsp;</p>
                    <section style="font-size: 1.8rem;">
                        <h3>Academic Service</h3>

                        <table style="width:100%; font-size:18px; border: 0;">
                            <tr style="height: 30px;">
                                <th>Associate Editor (AE):<th>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>Journal of Machine Vision and Applications (MVA)</li></ul></td>
                                <td>2023-present</td>
                            </tr>



                            <tr style="height: 30px;">
                                <th>Member of the Program Committee (PC):<th>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>The AAAI Conference on Artificial Intelligence (AAAI)</li></ul></td>
                                <td>2020-2024</td>
                            </tr>



                            <tr style="height: 30px;">
                                <th>Area Chair:<th>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>International Conference on Machine Learning (ICML)</li></ul></td>
                                <td>2025</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>Conference on Neural Information Processing Systems (NeurIPS)</li></ul></td>
                                <td>2024,2025</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</li></ul></td>
                                <td>2023,2024,2025</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>The 26th International Conference on Pattern Recognition (ICPR)</li></ul></td>
                                <td>2022,2023,2024</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE International Conference on Multimedia and Expo (ICME)</li></ul></td>
                                <td>2020,2021,2023</td>
                            </tr>



                            <tr style="height: 30px;">
                                <th>Conference Reviewer:<th>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</li></ul></td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE Int’l Conf. on Computer Vision (ICCV)</li></ul></td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>European Conf. on Computer Vision (ECCV)</li></ul></td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>Conference on Neural Information Processing Systems (NeurIPS)</li></ul></td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>International Conference on Learning Representations (ICLR)</li></ul></td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>International Conference on Machine Learning (ICML)</li></ul></td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>The AAAI Conference on Artificial Intelligence (AAAI)</li></ul></td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>British Machine Vision Conference (BMVC)</li></ul></td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE International Conference on Automatic Face and Gesture Recognition (FG)</li></ul></td>
                            </tr>



                            <tr style="height: 30px;">
                                <th>Journal Reviewer:<th>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE Trans on Pattern Analysis and Machine Intelligence (IEEE TPAMI)</li></ul></td>
                                <td>2015-present</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE Trans on Circuits and Systems for Video Technology (IEEE TCSVT)</li></ul></td>
                                <td>2016-present</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE Trans on Image Processing (IEEE TIP)</li></ul></td>
                                <td>2017-present</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>Computer Vision and Image Understanding (CVIU)</li></ul></td>
                                <td>2018-present</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE Transactions on Information Forensics & Security (IEEE TIFS)</li></ul></td>
                                <td>2019-present</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>International Journal of Computer Vision (IJCV)</li></ul></td>
                                <td>2019-present</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>Signal, Image and Video Processing (SIVP)</li></ul></td>
                                <td>2019-present</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>Neurocomputing (NEUCOM)</li></ul></td>
                                <td>2020-present</td>
                            </tr>
                            <tr style="height: 30px;">
                                <td><ul><li>IEEE Trans on Multimedia (IEEE TMM)</li></ul></td>
                                <td>2022-present</td>
                            </tr>
                        </table>
                </div>
            </div>
        </dic>
    </div>

    <script type="text/javascript" src="common/js/jquery.min.js"></script>
    <script type="text/javascript" src="common/js/bootstrap.min.js"></script>
    <Script>
        $('.moreclick').unbind().on('click',function(){
            $(this).hide();
            $('.more').show();
            $('.morehide').show();
        })
        $('.morehide').unbind().on('click',function(){
            $(this).hide();
            $(".moreclick").show();
            $('.more').hide();
        })
        $('.navbar-nav li').unbind().on('click',function(){
            if($(this).hasClass("active")){
                console.log(1)
            }else{
                $(this).addClass("active");
                $(this).siblings().removeClass('active');
            }
        })



        function showPapers(year) {
            // 获取所有论文列表和标签
            var paperLists = document.querySelectorAll('.paper-list');
            var tabs = document.querySelectorAll('.tab');
            
            // 隐藏所有论文列表
            paperLists.forEach(function(list) {
                list.classList.remove('active');
            });

            // 移除所有标签的激活状态
            tabs.forEach(function(tab) {
                tab.classList.remove('active');
            });

            // 显示选择的年份的论文列表
            document.getElementById(year).classList.add('active');

            // 设置当前标签为激活状态
            document.querySelector('.tab[onclick="showPapers(\'' + year + '\')"]').classList.add('active');
        }

        function showRecentPapers(year) {
            var currentYear = year;
            // var lastYear = currentYear - 1;
            
            // 显示当前年论文列表
            document.getElementById(currentYear).classList.add('active');
            // document.getElementById(lastYear).classList.add('active');

            // 激活当前年标签
            document.querySelector('.tab[onclick="showPapers(\'' + currentYear + '\')"]').classList.add('active');
            // document.querySelector('.tab[onclick="showPapers(\'' + lastYear + '\')"]').classList.add('active');
        }

        // 默认显示最近一年的论文
        showRecentPapers(2025);




        // 显示前5条新闻
        document.addEventListener("DOMContentLoaded", function() {
            var newsItems = document.querySelectorAll('.news-item');
            for (var i = 0; i < 6; i++) {
                if (newsItems[i]) {
                    newsItems[i].style.display = 'list-item';
                }
            }
        });


        document.getElementById('show-less').style.display = 'none'; // 隐藏Show Less按钮
        // Show More功能
        function showMoreNews() {
            var newsItems = document.querySelectorAll('.news-item');
            newsItems.forEach(function(item) {
                item.style.display = 'list-item'; // 显示所有新闻
            });
            document.getElementById('show-more').style.display = 'none'; // 隐藏Show More按钮
            document.getElementById('show-less').style.display = 'inline-block'; // 显示Show Less按钮
        }

        // Show Less功能
        function showLessNews() {
            var newsItems = document.querySelectorAll('.news-item');
            for (var i = 0; i < newsItems.length; i++) {
                if (i < 6) {
                    newsItems[i].style.display = 'list-item'; // 显示前5条新闻
                } else {
                    newsItems[i].style.display = 'none'; // 隐藏其他新闻
                }
            }
            document.getElementById('show-more').style.display = 'inline-block'; // 显示Show More按钮
            document.getElementById('show-less').style.display = 'none'; // 隐藏Show Less按钮
        }



        function copyTextAndNotify(event, text) {
            event.preventDefault();

            // 创建一个临时的textarea元素
            var textarea = document.createElement("textarea");
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            textarea.setSelectionRange(0, 99999); // 对于移动设备

            // 执行复制操作
            document.execCommand("copy");

            // 移除临时元素
            document.body.removeChild(textarea);

            // 显示提示信息
            var notification = document.getElementById("notification");
            notification.style.display = "block";

            // 3秒后隐藏提示信息
            setTimeout(function() {
                notification.style.display = "none";
            }, 3000);
        }
    </Script>
</body>
</html>
